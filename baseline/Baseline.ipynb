{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e5a814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T07:59:28.946357300Z",
     "start_time": "2024-04-11T07:59:26.739392400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c21bf0",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-11T07:59:30.552311800Z",
     "start_time": "2024-04-11T07:59:30.448288100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2298, 8)\n",
      "date            False\n",
      "turnoverVol     False\n",
      "CHG             False\n",
      "CHGPct          False\n",
      "openIndex       False\n",
      "highestIndex    False\n",
      "lowestIndex     False\n",
      "closeIndex      False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": "            date  turnoverVol    CHG  CHGPct  openIndex  highestIndex  \\\n2293  2018-12-20  120847000.0 -84.99 -1.7790    4709.75       4719.61   \n2294  2018-12-21  187129800.0   1.92  0.0409    4672.77       4696.18   \n2295  2018-12-24   24595900.0 -67.99 -1.4483    4650.42       4664.20   \n2296  2018-12-27   89451800.0 -27.78 -0.6005    4689.20       4692.43   \n2297  2018-12-28   67583000.0  80.13  1.7425    4641.05       4700.49   \n\n      lowestIndex  closeIndex  \n2293      4685.61     4692.46  \n2294      4628.24     4694.38  \n2295      4622.03     4626.39  \n2296      4555.99     4598.61  \n2297      4623.97     4678.74  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>turnoverVol</th>\n      <th>CHG</th>\n      <th>CHGPct</th>\n      <th>openIndex</th>\n      <th>highestIndex</th>\n      <th>lowestIndex</th>\n      <th>closeIndex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2293</th>\n      <td>2018-12-20</td>\n      <td>120847000.0</td>\n      <td>-84.99</td>\n      <td>-1.7790</td>\n      <td>4709.75</td>\n      <td>4719.61</td>\n      <td>4685.61</td>\n      <td>4692.46</td>\n    </tr>\n    <tr>\n      <th>2294</th>\n      <td>2018-12-21</td>\n      <td>187129800.0</td>\n      <td>1.92</td>\n      <td>0.0409</td>\n      <td>4672.77</td>\n      <td>4696.18</td>\n      <td>4628.24</td>\n      <td>4694.38</td>\n    </tr>\n    <tr>\n      <th>2295</th>\n      <td>2018-12-24</td>\n      <td>24595900.0</td>\n      <td>-67.99</td>\n      <td>-1.4483</td>\n      <td>4650.42</td>\n      <td>4664.20</td>\n      <td>4622.03</td>\n      <td>4626.39</td>\n    </tr>\n    <tr>\n      <th>2296</th>\n      <td>2018-12-27</td>\n      <td>89451800.0</td>\n      <td>-27.78</td>\n      <td>-0.6005</td>\n      <td>4689.20</td>\n      <td>4692.43</td>\n      <td>4555.99</td>\n      <td>4598.61</td>\n    </tr>\n    <tr>\n      <th>2297</th>\n      <td>2018-12-28</td>\n      <td>67583000.0</td>\n      <td>80.13</td>\n      <td>1.7425</td>\n      <td>4641.05</td>\n      <td>4700.49</td>\n      <td>4623.97</td>\n      <td>4678.74</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_stock = pd.read_csv('../ETT-small/price_FCHI.csv')\n",
    "# SZ_stock = pd.read_csv('Autoformer/ETT-small/price_SZ.csv')\n",
    "print(custom_stock.shape)\n",
    "print(custom_stock.isnull().any())\n",
    "custom_stock.tail()\n",
    "# SZ_stock.head()\n",
    "# prediction = custom_stock.iloc[-500:]\n",
    "# print(prediction.shape)\n",
    "# prediction.to_csv('Autoformer/ETT-small/price_prediction.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f7446d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SZ_stock.to_csv('price_SZ_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cda5ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(2298, 8)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_stock = custom_stock.drop(custom_stock[(custom_stock['CHG']==0) | (custom_stock['CHGPct']==0)].index) #删除x小于0.01或大于10的行\n",
    "custom_stock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda62e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1600x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(custom_stock['closeIndex'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5c0d9a9",
   "metadata": {
    "code_folding": [],
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382.3092306775678 1664.2605341777041\n",
      "(1812, 6)\n",
      "-1.3804022289558326\n",
      "(1807, 5, 6)\n",
      "(452, 5, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": "        CHG  CHGPct   openIndex  highestIndex  lowestIndex  closeIndex\n0  17.89001  1.6043  1116.56006    1133.87000   1116.56006  1132.98999\n1   3.53003  0.3116  1132.66003    1136.63000   1129.66003  1136.52002\n2   0.61999  0.0546  1135.70996    1139.18994   1133.94995  1137.14001\n3   4.54993  0.4001  1136.27002    1142.45996   1131.31995  1141.68994\n4   3.29004  0.2882  1140.52002    1145.39001   1136.21997  1144.97998",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CHG</th>\n      <th>CHGPct</th>\n      <th>openIndex</th>\n      <th>highestIndex</th>\n      <th>lowestIndex</th>\n      <th>closeIndex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.89001</td>\n      <td>1.6043</td>\n      <td>1116.56006</td>\n      <td>1133.87000</td>\n      <td>1116.56006</td>\n      <td>1132.98999</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.53003</td>\n      <td>0.3116</td>\n      <td>1132.66003</td>\n      <td>1136.63000</td>\n      <td>1129.66003</td>\n      <td>1136.52002</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.61999</td>\n      <td>0.0546</td>\n      <td>1135.70996</td>\n      <td>1139.18994</td>\n      <td>1133.94995</td>\n      <td>1137.14001</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.54993</td>\n      <td>0.4001</td>\n      <td>1136.27002</td>\n      <td>1142.45996</td>\n      <td>1131.31995</td>\n      <td>1141.68994</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.29004</td>\n      <td>0.2882</td>\n      <td>1140.52002</td>\n      <td>1145.39001</td>\n      <td>1136.21997</td>\n      <td>1144.97998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 时间点长度\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "time_stamp = 5\n",
    "# 划分训练集与验证集\n",
    "custom_stock = custom_stock[['CHG','CHGPct','openIndex','highestIndex','lowestIndex','closeIndex']]  #  'Volume'\n",
    "\n",
    "# custom_stock = custom_stock[['turnoverVol','turnoverValue','CHG','CHGPct','openIndex','highestIndex','lowestIndex','closeIndex']]  #  'Volume'\n",
    "total_len = custom_stock.shape[0]\n",
    "# valid_len = 1000\n",
    "valid_len = (int) (total_len*0.2)\n",
    "train_len = total_len - valid_len\n",
    "\n",
    "\n",
    "train = custom_stock[0:train_len]\n",
    "\n",
    "valid = custom_stock[train_len-time_stamp-1:-1]\n",
    "\n",
    "# 归一化\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit(train)\n",
    "global mean \n",
    "global std\n",
    "std = scaler.scale_[-1]\n",
    "mean = scaler.mean_[-1]\n",
    "print(std,mean)\n",
    "scaled_data = scaler.transform(train)\n",
    "x_train, y_train = [], []\n",
    "# print(scaled_data)\n",
    "\n",
    "# 训练集\n",
    "print(scaled_data.shape)\n",
    "print(scaled_data[1, -1])\n",
    "for i in range(time_stamp, len(train)):\n",
    "    x_train.append(scaled_data[i - time_stamp:i])\n",
    "    y_train.append(scaled_data[i, -1])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# 验证集\n",
    "scaled_data = scaler.transform(valid)\n",
    "# print(scaled_data)\n",
    "x_valid, y_valid = [], []\n",
    "for i in range(time_stamp, len(valid)):\n",
    "    x_valid.append(scaled_data[i - time_stamp:i])\n",
    "    y_valid.append(scaled_data[i, -1])\n",
    "\n",
    "x_valid, y_valid = np.array(x_valid), np.array(y_valid)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "# print(y_valid)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 1s 7ms/step - loss: 0.2238 - mae: 0.2238 - mse: 0.1374 - val_loss: 0.1652 - val_mae: 0.1652 - val_mse: 0.0374\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0482 - mae: 0.0482 - mse: 0.0041 - val_loss: 0.1227 - val_mae: 0.1227 - val_mse: 0.0220\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0362 - mae: 0.0362 - mse: 0.0024 - val_loss: 0.0772 - val_mae: 0.0772 - val_mse: 0.0103\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0325 - mae: 0.0325 - mse: 0.0020 - val_loss: 0.1533 - val_mae: 0.1533 - val_mse: 0.0303\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0330 - mae: 0.0330 - mse: 0.0019 - val_loss: 0.0982 - val_mae: 0.0982 - val_mse: 0.0143\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0324 - mae: 0.0324 - mse: 0.0019 - val_loss: 0.1500 - val_mae: 0.1500 - val_mse: 0.0290\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0323 - mae: 0.0323 - mse: 0.0019 - val_loss: 0.1154 - val_mae: 0.1154 - val_mse: 0.0186\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0323 - mae: 0.0323 - mse: 0.0019 - val_loss: 0.0650 - val_mae: 0.0650 - val_mse: 0.0076\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0304 - mae: 0.0304 - mse: 0.0017 - val_loss: 0.1455 - val_mae: 0.1455 - val_mse: 0.0270\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0309 - mae: 0.0309 - mse: 0.0017 - val_loss: 0.0750 - val_mae: 0.0750 - val_mse: 0.0093\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0298 - mae: 0.0298 - mse: 0.0016 - val_loss: 0.0648 - val_mae: 0.0648 - val_mse: 0.0073\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0307 - mae: 0.0307 - mse: 0.0017 - val_loss: 0.0860 - val_mae: 0.0860 - val_mse: 0.0115\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0315 - mae: 0.0315 - mse: 0.0018 - val_loss: 0.0684 - val_mae: 0.0684 - val_mse: 0.0080\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0304 - mae: 0.0304 - mse: 0.0017 - val_loss: 0.0545 - val_mae: 0.0545 - val_mse: 0.0053\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0299 - mae: 0.0299 - mse: 0.0016 - val_loss: 0.0530 - val_mae: 0.0530 - val_mse: 0.0050\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0300 - mae: 0.0300 - mse: 0.0017 - val_loss: 0.1084 - val_mae: 0.1084 - val_mse: 0.0164\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.0302 - mse: 0.0017 - val_loss: 0.1150 - val_mae: 0.1150 - val_mse: 0.0185\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0319 - mae: 0.0319 - mse: 0.0018 - val_loss: 0.1050 - val_mae: 0.1050 - val_mse: 0.0157\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.0292 - mse: 0.0016 - val_loss: 0.1033 - val_mae: 0.1033 - val_mse: 0.0151\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0303 - mae: 0.0303 - mse: 0.0016 - val_loss: 0.0575 - val_mae: 0.0575 - val_mse: 0.0063\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0320 - mae: 0.0320 - mse: 0.0018 - val_loss: 0.1786 - val_mae: 0.1786 - val_mse: 0.0386\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0308 - mae: 0.0308 - mse: 0.0017 - val_loss: 0.0723 - val_mae: 0.0723 - val_mse: 0.0085\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0300 - mae: 0.0300 - mse: 0.0016 - val_loss: 0.0541 - val_mae: 0.0541 - val_mse: 0.0050\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0322 - mae: 0.0322 - mse: 0.0018 - val_loss: 0.0760 - val_mae: 0.0760 - val_mse: 0.0097\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.0292 - mse: 0.0015 - val_loss: 0.0743 - val_mae: 0.0743 - val_mse: 0.0091\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0314 - mae: 0.0314 - mse: 0.0018 - val_loss: 0.1042 - val_mae: 0.1042 - val_mse: 0.0155\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0303 - mae: 0.0303 - mse: 0.0016 - val_loss: 0.0656 - val_mae: 0.0656 - val_mse: 0.0077\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0276 - mae: 0.0276 - mse: 0.0014 - val_loss: 0.0533 - val_mae: 0.0533 - val_mse: 0.0048\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0304 - mae: 0.0304 - mse: 0.0017 - val_loss: 0.1041 - val_mae: 0.1041 - val_mse: 0.0157\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0321 - mae: 0.0321 - mse: 0.0018 - val_loss: 0.0683 - val_mae: 0.0683 - val_mse: 0.0080\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0283 - mae: 0.0283 - mse: 0.0015 - val_loss: 0.1277 - val_mae: 0.1277 - val_mse: 0.0217\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0283 - mae: 0.0283 - mse: 0.0015 - val_loss: 0.0569 - val_mae: 0.0569 - val_mse: 0.0058\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0291 - mae: 0.0291 - mse: 0.0015 - val_loss: 0.0565 - val_mae: 0.0565 - val_mse: 0.0058\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0304 - mae: 0.0304 - mse: 0.0017 - val_loss: 0.1061 - val_mae: 0.1061 - val_mse: 0.0161\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0297 - mae: 0.0297 - mse: 0.0016 - val_loss: 0.0791 - val_mae: 0.0791 - val_mse: 0.0102\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0291 - mae: 0.0291 - mse: 0.0016 - val_loss: 0.1098 - val_mae: 0.1098 - val_mse: 0.0167\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0287 - mae: 0.0287 - mse: 0.0015 - val_loss: 0.0754 - val_mae: 0.0754 - val_mse: 0.0095\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.0280 - mse: 0.0014 - val_loss: 0.0638 - val_mae: 0.0638 - val_mse: 0.0074\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.0284 - mse: 0.0015 - val_loss: 0.0709 - val_mae: 0.0709 - val_mse: 0.0087\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0283 - mae: 0.0283 - mse: 0.0014 - val_loss: 0.1193 - val_mae: 0.1193 - val_mse: 0.0195\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.0281 - mse: 0.0014 - val_loss: 0.1074 - val_mae: 0.1074 - val_mse: 0.0163\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0291 - mae: 0.0291 - mse: 0.0015 - val_loss: 0.0740 - val_mae: 0.0740 - val_mse: 0.0092\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.0292 - mse: 0.0015 - val_loss: 0.1540 - val_mae: 0.1540 - val_mse: 0.0297\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0288 - mae: 0.0288 - mse: 0.0015 - val_loss: 0.0707 - val_mae: 0.0707 - val_mse: 0.0086\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0290 - mae: 0.0290 - mse: 0.0015 - val_loss: 0.1615 - val_mae: 0.1615 - val_mse: 0.0324\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0305 - mae: 0.0305 - mse: 0.0017 - val_loss: 0.0538 - val_mae: 0.0538 - val_mse: 0.0050\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0318 - mae: 0.0318 - mse: 0.0018 - val_loss: 0.0800 - val_mae: 0.0800 - val_mse: 0.0106\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0301 - mae: 0.0301 - mse: 0.0016 - val_loss: 0.1498 - val_mae: 0.1498 - val_mse: 0.0290\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0307 - mae: 0.0307 - mse: 0.0017 - val_loss: 0.0915 - val_mae: 0.0915 - val_mse: 0.0130\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0270 - mae: 0.0270 - mse: 0.0014 - val_loss: 0.0782 - val_mae: 0.0782 - val_mse: 0.0102\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0285 - mae: 0.0285 - mse: 0.0014 - val_loss: 0.1001 - val_mae: 0.1001 - val_mse: 0.0151\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0290 - mae: 0.0290 - mse: 0.0015 - val_loss: 0.0907 - val_mae: 0.0907 - val_mse: 0.0126\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0295 - mae: 0.0295 - mse: 0.0016 - val_loss: 0.0791 - val_mae: 0.0791 - val_mse: 0.0101\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0279 - mae: 0.0279 - mse: 0.0014 - val_loss: 0.0780 - val_mae: 0.0780 - val_mse: 0.0101\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0274 - mae: 0.0274 - mse: 0.0014 - val_loss: 0.0654 - val_mae: 0.0654 - val_mse: 0.0079\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0287 - mae: 0.0287 - mse: 0.0015 - val_loss: 0.1361 - val_mae: 0.1361 - val_mse: 0.0244\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0264 - mae: 0.0264 - mse: 0.0013 - val_loss: 0.0806 - val_mae: 0.0806 - val_mse: 0.0108\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.0292 - mse: 0.0015 - val_loss: 0.1090 - val_mae: 0.1090 - val_mse: 0.0173\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0277 - mae: 0.0277 - mse: 0.0014 - val_loss: 0.0761 - val_mae: 0.0761 - val_mse: 0.0097\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0271 - mae: 0.0271 - mse: 0.0014 - val_loss: 0.1038 - val_mae: 0.1038 - val_mse: 0.0155\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0272 - mae: 0.0272 - mse: 0.0013 - val_loss: 0.0678 - val_mae: 0.0678 - val_mse: 0.0079\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0273 - mae: 0.0273 - mse: 0.0014 - val_loss: 0.0987 - val_mae: 0.0987 - val_mse: 0.0146\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.0281 - mse: 0.0014 - val_loss: 0.0834 - val_mae: 0.0834 - val_mse: 0.0112\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.0289 - mse: 0.0015 - val_loss: 0.0580 - val_mae: 0.0580 - val_mse: 0.0062\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0279 - mae: 0.0279 - mse: 0.0014 - val_loss: 0.0974 - val_mae: 0.0974 - val_mse: 0.0140\n",
      "1.8859065331602543\n"
     ]
    }
   ],
   "source": [
    "#RC model\n",
    "import keras\n",
    "import  tensorflow as tf\n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D,Activation,Dropout,RNN\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "class ReservoirLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_units, **kwargs):\n",
    "        super(ReservoirLayer, self).__init__(**kwargs)\n",
    "        self.num_units = num_units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.reservoir_weights = self.add_weight(\n",
    "            shape=(input_shape[-1], self.num_units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=False,\n",
    "        )\n",
    "        self.reservoir_bias = self.add_weight(\n",
    "            shape=(self.num_units,),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=False,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        reservoir_output = tf.matmul(inputs, self.reservoir_weights) + self.reservoir_bias\n",
    "        reservoir_output = tf.nn.tanh(reservoir_output)\n",
    "        return reservoir_output\n",
    "\n",
    "\n",
    "# Create the Reservoir Computing model\n",
    "model = tf.keras.Sequential([\n",
    "    ReservoirLayer(num_units=128),\n",
    "    keras.layers.SimpleRNN(units=64,activation='relu'),\n",
    "    Dense(16),\n",
    "    Dense(1)\n",
    "\n",
    "])\n",
    "callbacks_list = [\n",
    "    # 目标指标不再有改善了，就可以提前终止\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,\n",
    "                                         verbose=0,mode='min',baseline=None,\n",
    "                                         restore_best_weights=True),\n",
    "    # 保存模型\n",
    "\n",
    "]\n",
    "EStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,\n",
    "                                         verbose=0,mode='min', baseline=None,\n",
    "                                         restore_best_weights=True\n",
    "                                         )\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=keras.losses.MAE, optimizer=adam, metrics=[\"mae\",\"mse\"])\n",
    "model.fit(x_train, y_train,\n",
    "                 epochs=epochs,validation_data=(x_valid, y_valid),\n",
    "                 batch_size=batch_size, verbose=1,\n",
    "                callbacks=[callbacks_list])\n",
    "# loss= model.evaluate(x_valid, u, verbose=0)\n",
    "# print(\"loss\",loss)\n",
    "# new_model = tf.keras.models.load_model('test.h5')\n",
    "\n",
    "print(y_valid[0])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e559751b",
   "metadata": {
    "code_folding": [
     12,
     17,
     94,
     125
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.8309 - mae: 0.8309 - mse: 1.0054 - val_loss: 2.2900 - val_mae: 2.2900 - val_mse: 5.3613\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8308 - mae: 0.8308 - mse: 1.0056 - val_loss: 2.1157 - val_mae: 2.1157 - val_mse: 4.5889\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8308 - mae: 0.8308 - mse: 1.0050 - val_loss: 2.2092 - val_mae: 2.2092 - val_mse: 4.9953\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0038 - val_loss: 2.2006 - val_mae: 2.2006 - val_mse: 4.9577\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0044 - val_loss: 2.1575 - val_mae: 2.1575 - val_mse: 4.7682\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8301 - mae: 0.8301 - mse: 1.0042 - val_loss: 2.2031 - val_mae: 2.2031 - val_mse: 4.9689\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0045 - val_loss: 2.1668 - val_mae: 2.1668 - val_mse: 4.8084\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0047 - val_loss: 2.2990 - val_mae: 2.2990 - val_mse: 5.4035\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8306 - mae: 0.8306 - mse: 1.0046 - val_loss: 2.1311 - val_mae: 2.1311 - val_mse: 4.6534\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8307 - mae: 0.8307 - mse: 1.0045 - val_loss: 2.2334 - val_mae: 2.2334 - val_mse: 5.1027\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0042 - val_loss: 2.1529 - val_mae: 2.1529 - val_mse: 4.7480\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8307 - mae: 0.8307 - mse: 1.0047 - val_loss: 2.1860 - val_mae: 2.1860 - val_mse: 4.8922\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0061 - val_loss: 2.1554 - val_mae: 2.1554 - val_mse: 4.7593\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8316 - mae: 0.8316 - mse: 1.0054 - val_loss: 2.1608 - val_mae: 2.1608 - val_mse: 4.7811\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8316 - mae: 0.8316 - mse: 1.0076 - val_loss: 2.2034 - val_mae: 2.2034 - val_mse: 4.9701\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0041 - val_loss: 2.2434 - val_mae: 2.2434 - val_mse: 5.1482\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0033 - val_loss: 2.1299 - val_mae: 2.1299 - val_mse: 4.6475\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8317 - mae: 0.8317 - mse: 1.0083 - val_loss: 2.1839 - val_mae: 2.1839 - val_mse: 4.8836\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0041 - val_loss: 2.2014 - val_mae: 2.2014 - val_mse: 4.9598\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8301 - mae: 0.8301 - mse: 1.0035 - val_loss: 2.2144 - val_mae: 2.2144 - val_mse: 5.0178\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0039 - val_loss: 2.2294 - val_mae: 2.2294 - val_mse: 5.0857\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8304 - mae: 0.8304 - mse: 1.0034 - val_loss: 2.2190 - val_mae: 2.2190 - val_mse: 5.0391\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8304 - mae: 0.8304 - mse: 1.0046 - val_loss: 2.2204 - val_mae: 2.2204 - val_mse: 5.0462\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0050 - val_loss: 2.1472 - val_mae: 2.1472 - val_mse: 4.7232\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0035 - val_loss: 2.1786 - val_mae: 2.1786 - val_mse: 4.8596\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0041 - val_loss: 2.2330 - val_mae: 2.2330 - val_mse: 5.1021\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8304 - mae: 0.8304 - mse: 1.0049 - val_loss: 2.2124 - val_mae: 2.2124 - val_mse: 5.0096\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8306 - mae: 0.8306 - mse: 1.0053 - val_loss: 2.2536 - val_mae: 2.2536 - val_mse: 5.1942\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8300 - mae: 0.8300 - mse: 1.0034 - val_loss: 2.0700 - val_mae: 2.0700 - val_mse: 4.3946\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8306 - mae: 0.8306 - mse: 1.0056 - val_loss: 2.2360 - val_mae: 2.2360 - val_mse: 5.1147\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8304 - mae: 0.8304 - mse: 1.0042 - val_loss: 2.1831 - val_mae: 2.1831 - val_mse: 4.8784\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8307 - mae: 0.8307 - mse: 1.0055 - val_loss: 2.1645 - val_mae: 2.1645 - val_mse: 4.7980\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8307 - mae: 0.8307 - mse: 1.0041 - val_loss: 2.1533 - val_mae: 2.1533 - val_mse: 4.7481\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0042 - val_loss: 2.1817 - val_mae: 2.1817 - val_mse: 4.8726\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0043 - val_loss: 2.1461 - val_mae: 2.1461 - val_mse: 4.7176\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0041 - val_loss: 2.1744 - val_mae: 2.1744 - val_mse: 4.8406\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8309 - mae: 0.8309 - mse: 1.0070 - val_loss: 2.1372 - val_mae: 2.1372 - val_mse: 4.6800\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0044 - val_loss: 2.2925 - val_mae: 2.2925 - val_mse: 5.3716\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0039 - val_loss: 2.1724 - val_mae: 2.1724 - val_mse: 4.8313\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8301 - mae: 0.8301 - mse: 1.0041 - val_loss: 2.1725 - val_mae: 2.1725 - val_mse: 4.8324\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8310 - mae: 0.8310 - mse: 1.0056 - val_loss: 2.0927 - val_mae: 2.0927 - val_mse: 4.4891\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8301 - mae: 0.8301 - mse: 1.0051 - val_loss: 2.2170 - val_mae: 2.2170 - val_mse: 5.0300\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8301 - mae: 0.8301 - mse: 1.0044 - val_loss: 2.1381 - val_mae: 2.1381 - val_mse: 4.6839\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0035 - val_loss: 2.1953 - val_mae: 2.1953 - val_mse: 4.9323\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8300 - mae: 0.8300 - mse: 1.0036 - val_loss: 2.1519 - val_mae: 2.1519 - val_mse: 4.7430\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0039 - val_loss: 2.1860 - val_mae: 2.1860 - val_mse: 4.8915\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8311 - mae: 0.8311 - mse: 1.0040 - val_loss: 2.0980 - val_mae: 2.0980 - val_mse: 4.5114\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8311 - mae: 0.8311 - mse: 1.0071 - val_loss: 2.1455 - val_mae: 2.1455 - val_mse: 4.7159\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8306 - mae: 0.8306 - mse: 1.0046 - val_loss: 2.1831 - val_mae: 2.1831 - val_mse: 4.8783\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0049 - val_loss: 2.2533 - val_mae: 2.2533 - val_mse: 5.1926\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8301 - mae: 0.8301 - mse: 1.0034 - val_loss: 2.1976 - val_mae: 2.1976 - val_mse: 4.9428\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8306 - mae: 0.8306 - mse: 1.0038 - val_loss: 2.2153 - val_mae: 2.2153 - val_mse: 5.0210\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8300 - mae: 0.8300 - mse: 1.0038 - val_loss: 2.1618 - val_mae: 2.1618 - val_mse: 4.7867\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8307 - mae: 0.8307 - mse: 1.0063 - val_loss: 2.0441 - val_mae: 2.0441 - val_mse: 4.2875\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0048 - val_loss: 2.1899 - val_mae: 2.1899 - val_mse: 4.9098\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0045 - val_loss: 2.2272 - val_mae: 2.2272 - val_mse: 5.0750\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0033 - val_loss: 2.1987 - val_mae: 2.1987 - val_mse: 4.9477\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0039 - val_loss: 2.1985 - val_mae: 2.1985 - val_mse: 4.9466\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8304 - mae: 0.8303 - mse: 1.0042 - val_loss: 2.1805 - val_mae: 2.1805 - val_mse: 4.8679\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0041 - val_loss: 2.1940 - val_mae: 2.1940 - val_mse: 4.9268\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8301 - mae: 0.8301 - mse: 1.0039 - val_loss: 2.1498 - val_mae: 2.1498 - val_mse: 4.7349\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0039 - val_loss: 2.1559 - val_mae: 2.1559 - val_mse: 4.7597\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8307 - mae: 0.8307 - mse: 1.0062 - val_loss: 2.1374 - val_mae: 2.1374 - val_mse: 4.6811\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8308 - mae: 0.8308 - mse: 1.0050 - val_loss: 2.0925 - val_mae: 2.0925 - val_mse: 4.4884\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8310 - mae: 0.8310 - mse: 1.0070 - val_loss: 2.1664 - val_mae: 2.1664 - val_mse: 4.8062\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0041 - val_loss: 2.2423 - val_mae: 2.2423 - val_mse: 5.1426\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8306 - mae: 0.8306 - mse: 1.0046 - val_loss: 2.2105 - val_mae: 2.2105 - val_mse: 4.9998\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8308 - mae: 0.8308 - mse: 1.0046 - val_loss: 2.1202 - val_mae: 2.1202 - val_mse: 4.6057\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8304 - mae: 0.8304 - mse: 1.0050 - val_loss: 2.1316 - val_mae: 2.1316 - val_mse: 4.6552\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0045 - val_loss: 2.1387 - val_mae: 2.1387 - val_mse: 4.6851\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0039 - val_loss: 2.1816 - val_mae: 2.1816 - val_mse: 4.8710\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8304 - mae: 0.8304 - mse: 1.0042 - val_loss: 2.1949 - val_mae: 2.1949 - val_mse: 4.9305\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0040 - val_loss: 2.1640 - val_mae: 2.1640 - val_mse: 4.7946\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8304 - mae: 0.8304 - mse: 1.0037 - val_loss: 2.1863 - val_mae: 2.1863 - val_mse: 4.8922\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8299 - mae: 0.8299 - mse: 1.0035 - val_loss: 2.0855 - val_mae: 2.0855 - val_mse: 4.4590\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8305 - mae: 0.8305 - mse: 1.0053 - val_loss: 2.0862 - val_mae: 2.0862 - val_mse: 4.4630\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8304 - mae: 0.8304 - mse: 1.0044 - val_loss: 2.1883 - val_mae: 2.1883 - val_mse: 4.9020\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8307 - mae: 0.8307 - mse: 1.0060 - val_loss: 2.2408 - val_mae: 2.2408 - val_mse: 5.1363\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0047 - val_loss: 2.1954 - val_mae: 2.1954 - val_mse: 4.9335\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8300 - mae: 0.8300 - mse: 1.0035 - val_loss: 2.0903 - val_mae: 2.0903 - val_mse: 4.4790\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8307 - mae: 0.8307 - mse: 1.0046 - val_loss: 2.1688 - val_mae: 2.1688 - val_mse: 4.8161\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8307 - mae: 0.8307 - mse: 1.0056 - val_loss: 2.2682 - val_mae: 2.2682 - val_mse: 5.2605\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0047 - val_loss: 2.2041 - val_mae: 2.2041 - val_mse: 4.9717\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0037 - val_loss: 2.2040 - val_mae: 2.2040 - val_mse: 4.9709\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8318 - mae: 0.8318 - mse: 1.0097 - val_loss: 2.0711 - val_mae: 2.0711 - val_mse: 4.3993\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8311 - mae: 0.8311 - mse: 1.0067 - val_loss: 2.1119 - val_mae: 2.1119 - val_mse: 4.5703\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8303 - mae: 0.8303 - mse: 1.0039 - val_loss: 2.2189 - val_mae: 2.2189 - val_mse: 5.0369\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8308 - mae: 0.8308 - mse: 1.0057 - val_loss: 2.1796 - val_mae: 2.1796 - val_mse: 4.8632\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8300 - mae: 0.8300 - mse: 1.0032 - val_loss: 2.0922 - val_mae: 2.0922 - val_mse: 4.4872\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8313 - mae: 0.8313 - mse: 1.0066 - val_loss: 2.1001 - val_mae: 2.1001 - val_mse: 4.5202\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0036 - val_loss: 2.1632 - val_mae: 2.1632 - val_mse: 4.7915\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8301 - mae: 0.8301 - mse: 1.0040 - val_loss: 2.1614 - val_mae: 2.1614 - val_mse: 4.7837\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0041 - val_loss: 2.1596 - val_mae: 2.1596 - val_mse: 4.7752\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8307 - mae: 0.8307 - mse: 1.0054 - val_loss: 2.2047 - val_mae: 2.2047 - val_mse: 4.9742\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8304 - mae: 0.8304 - mse: 1.0038 - val_loss: 2.1641 - val_mae: 2.1641 - val_mse: 4.7951\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8299 - mae: 0.8299 - mse: 1.0034 - val_loss: 2.0759 - val_mae: 2.0759 - val_mse: 4.4187\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8301 - mae: 0.8301 - mse: 1.0041 - val_loss: 2.1556 - val_mae: 2.1556 - val_mse: 4.7584\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8302 - mae: 0.8302 - mse: 1.0052 - val_loss: 2.1919 - val_mae: 2.1919 - val_mse: 4.9183\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8306 - mae: 0.8306 - mse: 1.0045 - val_loss: 2.0889 - val_mae: 2.0889 - val_mse: 4.4736\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8306 - mae: 0.8306 - mse: 1.0053 - val_loss: 2.0835 - val_mae: 2.0835 - val_mse: 4.4513\n",
      "1.7066514221167588\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "#CNN\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D,Activation,Dropout,RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "def R2(pred, true):\n",
    "    return 1 - (np.sum((true-pred)**2)) / (np.sum((true-true.mean())**2))\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = tf.keras.initializers.get('glorot_uniform')\n",
    "        # W_regularizer: 权重上的正则化\n",
    "        # b_regularizer: 偏置项的正则化\n",
    "        self.W_regularizer = tf.keras.regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = tf.keras.regularizers.get(b_regularizer)\n",
    "        # W_constraint: 权重上的约束项\n",
    "        # b_constraint: 偏置上的约束项\n",
    "        self.W_constraint = tf.keras.constraints.get(W_constraint)\n",
    "        self.b_constraint = tf.keras.constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        \n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        \n",
    "        if self.bias:\n",
    "                    self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "            \n",
    "        self.built = True\n",
    "        \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "        \n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                              K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "        \n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "            \n",
    "        eij = K.tanh(eij)\n",
    "        \n",
    "        a = K.exp(eij)\n",
    "        \n",
    "        '''\n",
    "        keras.backend.cast(x, dtype): 将张量转换到不同的 dtype 并返回\n",
    "        '''\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "            \n",
    "        '''\n",
    "        keras.backend.epsilon(): 返回浮点数\n",
    "        '''\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon()   , K.floatx())\n",
    "        \n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim\n",
    "\n",
    "class CustomEarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomEarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"val_loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            print(\"learning_rate: \",self.learning_rate)\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# print(y_valid)\n",
    "\n",
    "# LSTM 参数: return_sequences=True LSTM输出为一个序列。默认为False，输出一个值。\n",
    "# input_dim： 输入单个样本特征值的维度\n",
    "# input_length： 输入的时间点长度\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64,kernel_size=1,activation='tanh'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(1))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(LSTM(units=64, return_sequences=True, input_dim=x_train.shape[-1], input_length=x_train.shape[1],activation='tanh'))\n",
    "# model.add(keras.layers.Bidirectional(LSTM(units=64,return_sequences=False,activation='tanh')))\n",
    "# model.add(keras.layers.LSTM(units=164,return_sequences=False,activation='tanh'))\n",
    "# model.add(keras.layers.SimpleRNN(units=64,activation='tanh'))\n",
    "# model.add(Attention(5))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "callbacks_list = [\n",
    "    # 目标指标不再有改善了，就可以提前终止\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,\n",
    "                                         verbose=0,mode='min',baseline=None,\n",
    "                                         restore_best_weights=True),\n",
    "    # 保存模型\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'test.h5', # 文件路径\n",
    "    monitor='val_loss', # 如果val_loss 没有改善就不覆盖\n",
    "    save_best_only=True) # 保持最佳模型\n",
    "    \n",
    "]\n",
    "EStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,\n",
    "                                         verbose=0,mode='min', baseline=None,\n",
    "                                         restore_best_weights=True\n",
    "                                         )\n",
    "Learn_rate_adjust = tf.keras.callbacks.LearningRateScheduler(scheduler) \n",
    "\n",
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=x_train.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "# optimizer_ad = AdamWarmup(total_steps, warmup_steps, learning_rate=1e-3, min_lr=1e-7)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=keras.losses.MAE, optimizer=adam, metrics=[\"mae\",\"mse\"])\n",
    "hist = model.fit(x_train, y_train, \n",
    "                 epochs=epochs,validation_data=(x_valid, y_valid), \n",
    "                 batch_size=batch_size, verbose=1,\n",
    "                callbacks=[callbacks_list])\n",
    "# loss= model.evaluate(x_valid, u, verbose=0)\n",
    "# print(\"loss\",loss)\n",
    "new_model = tf.keras.models.load_model('test.h5')\n",
    "\n",
    "print(y_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4183bdc",
   "metadata": {
    "code_folding": [
     17,
     91,
     94
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 1s 7ms/step - loss: 0.2432 - mae: 0.2432 - mse: 0.1507 - val_loss: 2625.6917 - val_mae: 2625.6917 - val_mse: 6921098.0000\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0642 - mae: 0.0642 - mse: 0.0085 - val_loss: 2625.7756 - val_mae: 2625.7756 - val_mse: 6921546.0000\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0455 - mae: 0.0455 - mse: 0.0040 - val_loss: 2625.7830 - val_mae: 2625.7830 - val_mse: 6921582.5000\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0402 - mae: 0.0402 - mse: 0.0031 - val_loss: 2625.7556 - val_mae: 2625.7556 - val_mse: 6921435.0000\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0377 - mae: 0.0377 - mse: 0.0027 - val_loss: 2625.8870 - val_mae: 2625.8870 - val_mse: 6922135.0000\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0394 - mae: 0.0394 - mse: 0.0029 - val_loss: 2625.7942 - val_mae: 2625.7942 - val_mse: 6921641.5000\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0337 - mae: 0.0337 - mse: 0.0021 - val_loss: 2625.7029 - val_mae: 2625.7029 - val_mse: 6921157.0000\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0337 - mae: 0.0337 - mse: 0.0021 - val_loss: 2625.7737 - val_mae: 2625.7737 - val_mse: 6921532.5000\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0322 - mae: 0.0322 - mse: 0.0019 - val_loss: 2625.8682 - val_mae: 2625.8682 - val_mse: 6922033.5000\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0344 - mae: 0.0344 - mse: 0.0021 - val_loss: 2625.7588 - val_mae: 2625.7588 - val_mse: 6921452.5000\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0323 - mae: 0.0323 - mse: 0.0020 - val_loss: 2625.7441 - val_mae: 2625.7441 - val_mse: 6921376.5000\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0361 - mae: 0.0361 - mse: 0.0023 - val_loss: 2625.8374 - val_mae: 2625.8374 - val_mse: 6921868.0000\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0340 - mae: 0.0340 - mse: 0.0021 - val_loss: 2625.7949 - val_mae: 2625.7949 - val_mse: 6921643.0000\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0310 - mae: 0.0310 - mse: 0.0018 - val_loss: 2625.7058 - val_mae: 2625.7058 - val_mse: 6921171.5000\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.0292 - mse: 0.0016 - val_loss: 2625.7839 - val_mae: 2625.7839 - val_mse: 6921586.5000\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.0302 - mse: 0.0016 - val_loss: 2625.6687 - val_mae: 2625.6687 - val_mse: 6920974.0000\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0327 - mae: 0.0327 - mse: 0.0019 - val_loss: 2625.7119 - val_mae: 2625.7119 - val_mse: 6921203.0000\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0301 - mae: 0.0301 - mse: 0.0016 - val_loss: 2625.7888 - val_mae: 2625.7888 - val_mse: 6921611.5000\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.0292 - mse: 0.0016 - val_loss: 2625.8398 - val_mae: 2625.8398 - val_mse: 6921883.0000\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0299 - mae: 0.0299 - mse: 0.0016 - val_loss: 2625.8213 - val_mae: 2625.8213 - val_mse: 6921786.5000\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.0293 - mse: 0.0016 - val_loss: 2625.8076 - val_mae: 2625.8076 - val_mse: 6921711.0000\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0302 - mae: 0.0302 - mse: 0.0017 - val_loss: 2625.7925 - val_mae: 2625.7925 - val_mse: 6921631.0000\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0279 - mae: 0.0279 - mse: 0.0015 - val_loss: 2625.7205 - val_mae: 2625.7205 - val_mse: 6921249.0000\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.0289 - mse: 0.0015 - val_loss: 2625.7881 - val_mae: 2625.7881 - val_mse: 6921609.0000\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0304 - mae: 0.0304 - mse: 0.0016 - val_loss: 2625.8845 - val_mae: 2625.8845 - val_mse: 6922121.0000\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0286 - mae: 0.0286 - mse: 0.0015 - val_loss: 2625.8057 - val_mae: 2625.8057 - val_mse: 6921699.0000\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0285 - mae: 0.0285 - mse: 0.0015 - val_loss: 2625.7732 - val_mae: 2625.7732 - val_mse: 6921528.5000\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0291 - mae: 0.0291 - mse: 0.0016 - val_loss: 2625.7949 - val_mae: 2625.7949 - val_mse: 6921643.5000\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0295 - mae: 0.0295 - mse: 0.0016 - val_loss: 2625.7847 - val_mae: 2625.7847 - val_mse: 6921590.0000\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.0284 - mse: 0.0015 - val_loss: 2625.7454 - val_mae: 2625.7454 - val_mse: 6921381.0000\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0282 - mae: 0.0282 - mse: 0.0015 - val_loss: 2625.8315 - val_mae: 2625.8315 - val_mse: 6921839.0000\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0271 - mae: 0.0271 - mse: 0.0014 - val_loss: 2625.7556 - val_mae: 2625.7556 - val_mse: 6921436.0000\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0278 - mae: 0.0278 - mse: 0.0015 - val_loss: 2625.7932 - val_mae: 2625.7932 - val_mse: 6921635.5000\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.0284 - mse: 0.0014 - val_loss: 2625.8318 - val_mae: 2625.8318 - val_mse: 6921841.5000\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0282 - mae: 0.0282 - mse: 0.0014 - val_loss: 2625.7295 - val_mae: 2625.7295 - val_mse: 6921297.5000\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0276 - mae: 0.0276 - mse: 0.0014 - val_loss: 2625.7964 - val_mae: 2625.7964 - val_mse: 6921653.0000\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0268 - mae: 0.0268 - mse: 0.0013 - val_loss: 2625.7249 - val_mae: 2625.7249 - val_mse: 6921273.0000\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0279 - mae: 0.0279 - mse: 0.0015 - val_loss: 2625.8376 - val_mae: 2625.8376 - val_mse: 6921871.5000\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0276 - mae: 0.0276 - mse: 0.0014 - val_loss: 2625.8015 - val_mae: 2625.8015 - val_mse: 6921680.5000\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0264 - mae: 0.0264 - mse: 0.0013 - val_loss: 2625.7815 - val_mae: 2625.7815 - val_mse: 6921574.5000\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0264 - mae: 0.0264 - mse: 0.0013 - val_loss: 2625.7732 - val_mae: 2625.7732 - val_mse: 6921530.5000\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0013 - val_loss: 2625.7676 - val_mae: 2625.7676 - val_mse: 6921501.0000\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0256 - mae: 0.0256 - mse: 0.0012 - val_loss: 2625.7949 - val_mae: 2625.7949 - val_mse: 6921642.0000\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0013 - val_loss: 2625.8020 - val_mae: 2625.8020 - val_mse: 6921683.5000\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0271 - mae: 0.0271 - mse: 0.0013 - val_loss: 2625.8035 - val_mae: 2625.8035 - val_mse: 6921688.0000\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0013 - val_loss: 2625.7546 - val_mae: 2625.7546 - val_mse: 6921432.0000\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0261 - mae: 0.0261 - mse: 0.0013 - val_loss: 2625.7759 - val_mae: 2625.7759 - val_mse: 6921545.0000\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0267 - mae: 0.0267 - mse: 0.0013 - val_loss: 2625.7595 - val_mae: 2625.7595 - val_mse: 6921457.5000\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0274 - mae: 0.0274 - mse: 0.0014 - val_loss: 2625.7756 - val_mae: 2625.7756 - val_mse: 6921543.5000\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0012 - val_loss: 2625.6938 - val_mae: 2625.6938 - val_mse: 6921109.5000\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.0293 - mse: 0.0015 - val_loss: 2625.8325 - val_mae: 2625.8325 - val_mse: 6921843.5000\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0264 - mae: 0.0264 - mse: 0.0013 - val_loss: 2625.7341 - val_mae: 2625.7341 - val_mse: 6921323.0000\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0255 - mae: 0.0255 - mse: 0.0012 - val_loss: 2625.7502 - val_mae: 2625.7502 - val_mse: 6921409.0000\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0012 - val_loss: 2625.7854 - val_mae: 2625.7854 - val_mse: 6921595.5000\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0266 - mae: 0.0266 - mse: 0.0013 - val_loss: 2625.7908 - val_mae: 2625.7908 - val_mse: 6921621.0000\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0012 - val_loss: 2625.7769 - val_mae: 2625.7769 - val_mse: 6921549.0000\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.0245 - mse: 0.0012 - val_loss: 2625.7512 - val_mae: 2625.7512 - val_mse: 6921412.5000\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0265 - mae: 0.0265 - mse: 0.0013 - val_loss: 2625.7263 - val_mae: 2625.7263 - val_mse: 6921281.0000\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0264 - mae: 0.0264 - mse: 0.0013 - val_loss: 2625.7651 - val_mae: 2625.7651 - val_mse: 6921486.0000\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0264 - mae: 0.0264 - mse: 0.0013 - val_loss: 2625.7478 - val_mae: 2625.7478 - val_mse: 6921394.0000\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0283 - mae: 0.0283 - mse: 0.0015 - val_loss: 2625.7852 - val_mae: 2625.7852 - val_mse: 6921593.0000\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0272 - mae: 0.0272 - mse: 0.0013 - val_loss: 2625.7361 - val_mae: 2625.7361 - val_mse: 6921336.0000\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0012 - val_loss: 2625.7744 - val_mae: 2625.7744 - val_mse: 6921536.0000\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.0245 - mse: 0.0012 - val_loss: 2625.7554 - val_mae: 2625.7554 - val_mse: 6921436.5000\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0012 - val_loss: 2625.7554 - val_mae: 2625.7554 - val_mse: 6921434.5000\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0250 - mae: 0.0250 - mse: 0.0012 - val_loss: 2625.7759 - val_mae: 2625.7759 - val_mse: 6921545.5000\n",
      "2385.26001\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "#RNN\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D,Activation,Dropout,RNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "def R2(pred, true):\n",
    "    return 1 - (np.sum((true-pred)**2)) / (np.sum((true-true.mean())**2))\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = tf.keras.initializers.get('glorot_uniform')\n",
    "        # W_regularizer: 权重上的正则化\n",
    "        # b_regularizer: 偏置项的正则化\n",
    "        self.W_regularizer = tf.keras.regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = tf.keras.regularizers.get(b_regularizer)\n",
    "        # W_constraint: 权重上的约束项\n",
    "        # b_constraint: 偏置上的约束项\n",
    "        self.W_constraint = tf.keras.constraints.get(W_constraint)\n",
    "        self.b_constraint = tf.keras.constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        \n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        \n",
    "        if self.bias:\n",
    "                    self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "            \n",
    "        self.built = True\n",
    "        \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "        \n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                              K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "        \n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "            \n",
    "        eij = K.tanh(eij)\n",
    "        \n",
    "        a = K.exp(eij)\n",
    "        \n",
    "        '''\n",
    "        keras.backend.cast(x, dtype): 将张量转换到不同的 dtype 并返回\n",
    "        '''\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "            \n",
    "        '''\n",
    "        keras.backend.epsilon(): 返回浮点数\n",
    "        '''\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon()   , K.floatx())\n",
    "        \n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim\n",
    "\n",
    "class CustomEarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomEarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"val_loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            print(\"learning_rate: \",self.learning_rate)\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# print(y_valid)\n",
    "\n",
    "# LSTM 参数: return_sequences=True LSTM输出为一个序列。默认为False，输出一个值。\n",
    "# input_dim： 输入单个样本特征值的维度\n",
    "# input_length： 输入的时间点长度\n",
    "model = Sequential()\n",
    "# model.add(Conv1D(filters=64,kernel_size=1,activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(MaxPooling1D(1))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(LSTM(units=64, return_sequences=True, input_dim=x_train.shape[-1], input_length=x_train.shape[1],activation='tanh'))\n",
    "# model.add(keras.layers.Bidirectional(LSTM(units=64,return_sequences=False,activation='tanh')))\n",
    "# model.add(keras.layers.LSTM(units=164,return_sequences=False,activation='tanh'))\n",
    "model.add(keras.layers.SimpleRNN(units=64,activation='relu'))\n",
    "model.add(Dense(16))\n",
    "# model.add(Attention(5))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "callbacks_list = [\n",
    "    # 目标指标不再有改善了，就可以提前终止\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,\n",
    "                                         verbose=0,mode='min',baseline=None,\n",
    "                                         restore_best_weights=True),\n",
    "    # 保存模型\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'test.h5', # 文件路径\n",
    "    monitor='val_loss', # 如果val_loss 没有改善就不覆盖\n",
    "    save_best_only=True) # 保持最佳模型\n",
    "    \n",
    "]\n",
    "EStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,\n",
    "                                         verbose=0,mode='min', baseline=None,\n",
    "                                         restore_best_weights=True\n",
    "                                         )\n",
    "Learn_rate_adjust = tf.keras.callbacks.LearningRateScheduler(scheduler) \n",
    "\n",
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=x_train.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "# optimizer_ad = AdamWarmup(total_steps, warmup_steps, learning_rate=1e-3, min_lr=1e-7)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=keras.losses.MAE, optimizer=adam, metrics=[\"mae\",\"mse\"])\n",
    "hist = model.fit(x_train, y_train, \n",
    "                 epochs=epochs,validation_data=(x_valid, y_valid), \n",
    "                 batch_size=batch_size, verbose=1,\n",
    "                callbacks=[callbacks_list])\n",
    "# loss= model.evaluate(x_valid, u, verbose=0)\n",
    "# print(\"loss\",loss)\n",
    "new_model = tf.keras.models.load_model('test.h5')\n",
    "\n",
    "print(y_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77dae66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2061951905488968, 0.04709579050540924, 0.040935125201940536, 0.03937966004014015, 0.037464432418346405, 0.03793541342020035, 0.035842444747686386, 0.03417360782623291, 0.036062419414520264, 0.03329167515039444, 0.03403981775045395, 0.035778436809778214, 0.031034080311655998, 0.031488947570323944, 0.03087908774614334, 0.03134096786379814, 0.0315997451543808, 0.031002318486571312, 0.031114695593714714, 0.03069830685853958, 0.02973872795701027, 0.03073178045451641, 0.030819838866591454, 0.03029222972691059, 0.031177913770079613, 0.030957425013184547, 0.029788633808493614, 0.03076297603547573, 0.029307352378964424, 0.029489781707525253, 0.03048798441886902, 0.029719509184360504, 0.02938377484679222, 0.029254918918013573, 0.029393212869763374, 0.030182354152202606, 0.028721433132886887, 0.03156566992402077, 0.028859708458185196, 0.029996734112501144, 0.03185740113258362, 0.02956295572221279, 0.028301188722252846, 0.029495390132069588, 0.028525380417704582, 0.029217112809419632, 0.02912314608693123, 0.029701394960284233, 0.029341867193579674, 0.027628323063254356, 0.028764454647898674, 0.030248071998357773, 0.029445886611938477, 0.03004753775894642, 0.028276914730668068, 0.028324758633971214, 0.027892719954252243, 0.029430391266942024, 0.028378229588270187, 0.028209520503878593, 0.029386458918452263, 0.0277275200933218, 0.028574327006936073, 0.02805686928331852, 0.02828717604279518, 0.028877973556518555, 0.028317108750343323, 0.028386486694216728, 0.028552111238241196, 0.028429336845874786, 0.02858424186706543, 0.028830159455537796, 0.028490735217928886, 0.028306055814027786, 0.02886456623673439, 0.028058122843503952, 0.028953244909644127, 0.02884405106306076, 0.028848018497228622, 0.028631137683987617, 0.02778485417366028, 0.02756529673933983, 0.02758684568107128, 0.027491090819239616, 0.027780788019299507, 0.02831581048667431, 0.027975421398878098, 0.028434839099645615, 0.028891807422041893, 0.027354639023542404, 0.029108259826898575, 0.026972251012921333, 0.028248531743884087, 0.02776346728205681, 0.028605593368411064, 0.027262970805168152, 0.02793722040951252, 0.027854880318045616, 0.02820598892867565, 0.028780190274119377]\n"
     ]
    }
   ],
   "source": [
    "print(hist.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cf02a3e",
   "metadata": {
    "code_folding": [
     17,
     94
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 85ms/step - loss: 0.8274 - mae: 0.8274 - mse: 1.1359 - val_loss: 2.6753 - val_mae: 2.6753 - val_mse: 10.1368\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4923 - mae: 0.4923 - mse: 0.4441 - val_loss: 1.9202 - val_mae: 1.9202 - val_mse: 6.0178\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2522 - mae: 0.2522 - mse: 0.1177 - val_loss: 1.4810 - val_mae: 1.4810 - val_mse: 4.2048\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2446 - mae: 0.2446 - mse: 0.1005 - val_loss: 1.6291 - val_mae: 1.6291 - val_mse: 4.8358\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1818 - mae: 0.1818 - mse: 0.0572 - val_loss: 1.6588 - val_mae: 1.6588 - val_mse: 4.9933\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1705 - mae: 0.1705 - mse: 0.0512 - val_loss: 1.5272 - val_mae: 1.5272 - val_mse: 4.2754\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1546 - mae: 0.1546 - mse: 0.0427 - val_loss: 1.3550 - val_mae: 1.3550 - val_mse: 3.5404\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1517 - mae: 0.1517 - mse: 0.0396 - val_loss: 1.3010 - val_mae: 1.3010 - val_mse: 3.2931\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1459 - mae: 0.1459 - mse: 0.0375 - val_loss: 1.3011 - val_mae: 1.3011 - val_mse: 3.2600\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1453 - mae: 0.1453 - mse: 0.0376 - val_loss: 1.2924 - val_mae: 1.2924 - val_mse: 3.2147\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1436 - mae: 0.1436 - mse: 0.0360 - val_loss: 1.2456 - val_mae: 1.2456 - val_mse: 3.0324\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1459 - mae: 0.1459 - mse: 0.0387 - val_loss: 1.2044 - val_mae: 1.2044 - val_mse: 2.8315\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1418 - mae: 0.1418 - mse: 0.0361 - val_loss: 1.1617 - val_mae: 1.1617 - val_mse: 2.6845\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1404 - mae: 0.1404 - mse: 0.0347 - val_loss: 1.0860 - val_mae: 1.0860 - val_mse: 2.4123\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1388 - mae: 0.1388 - mse: 0.0344 - val_loss: 1.0640 - val_mae: 1.0640 - val_mse: 2.3360\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1380 - mae: 0.1380 - mse: 0.0340 - val_loss: 1.1105 - val_mae: 1.1105 - val_mse: 2.4859\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1374 - mae: 0.1374 - mse: 0.0338 - val_loss: 1.0227 - val_mae: 1.0227 - val_mse: 2.1922\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1373 - mae: 0.1373 - mse: 0.0338 - val_loss: 1.0056 - val_mae: 1.0056 - val_mse: 2.1292\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1370 - mae: 0.1370 - mse: 0.0341 - val_loss: 0.9907 - val_mae: 0.9907 - val_mse: 2.0677\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1368 - mae: 0.1368 - mse: 0.0339 - val_loss: 0.8798 - val_mae: 0.8798 - val_mse: 1.7462\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1392 - mae: 0.1392 - mse: 0.0348 - val_loss: 1.0062 - val_mae: 1.0062 - val_mse: 2.1066\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1393 - mae: 0.1393 - mse: 0.0346 - val_loss: 1.0310 - val_mae: 1.0310 - val_mse: 2.1750\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1388 - mae: 0.1388 - mse: 0.0343 - val_loss: 0.9302 - val_mae: 0.9302 - val_mse: 1.8813\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1351 - mae: 0.1351 - mse: 0.0330 - val_loss: 1.0002 - val_mae: 1.0002 - val_mse: 2.0865\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1362 - mae: 0.1362 - mse: 0.0338 - val_loss: 0.9914 - val_mae: 0.9914 - val_mse: 2.0670\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1343 - mae: 0.1343 - mse: 0.0332 - val_loss: 0.8963 - val_mae: 0.8963 - val_mse: 1.7945\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1358 - mae: 0.1358 - mse: 0.0340 - val_loss: 0.9631 - val_mae: 0.9631 - val_mse: 1.9967\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1370 - mae: 0.1370 - mse: 0.0338 - val_loss: 1.0756 - val_mae: 1.0756 - val_mse: 2.3538\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1468 - mae: 0.1468 - mse: 0.0391 - val_loss: 0.9866 - val_mae: 0.9866 - val_mse: 2.0836\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1398 - mae: 0.1398 - mse: 0.0360 - val_loss: 0.9167 - val_mae: 0.9167 - val_mse: 1.8397\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1384 - mae: 0.1384 - mse: 0.0358 - val_loss: 0.9115 - val_mae: 0.9115 - val_mse: 1.8458\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1369 - mae: 0.1369 - mse: 0.0342 - val_loss: 1.0005 - val_mae: 1.0005 - val_mse: 2.0977\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1368 - mae: 0.1368 - mse: 0.0342 - val_loss: 0.9035 - val_mae: 0.9035 - val_mse: 1.8039\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1347 - mae: 0.1347 - mse: 0.0336 - val_loss: 0.8632 - val_mae: 0.8632 - val_mse: 1.6899\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1346 - mae: 0.1346 - mse: 0.0336 - val_loss: 0.9139 - val_mae: 0.9139 - val_mse: 1.8376\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1336 - mae: 0.1336 - mse: 0.0330 - val_loss: 0.9277 - val_mae: 0.9277 - val_mse: 1.8875\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1332 - mae: 0.1332 - mse: 0.0330 - val_loss: 0.9105 - val_mae: 0.9105 - val_mse: 1.8320\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1447 - mae: 0.1447 - mse: 0.0386 - val_loss: 0.9468 - val_mae: 0.9468 - val_mse: 1.9262\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1339 - mae: 0.1339 - mse: 0.0335 - val_loss: 0.9384 - val_mae: 0.9384 - val_mse: 1.9293\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1378 - mae: 0.1378 - mse: 0.0338 - val_loss: 0.9220 - val_mae: 0.9220 - val_mse: 1.8583\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1352 - mae: 0.1352 - mse: 0.0336 - val_loss: 0.8279 - val_mae: 0.8279 - val_mse: 1.5919\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1354 - mae: 0.1354 - mse: 0.0336 - val_loss: 0.8720 - val_mae: 0.8720 - val_mse: 1.7136\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1354 - mae: 0.1354 - mse: 0.0332 - val_loss: 0.8657 - val_mae: 0.8657 - val_mse: 1.6907\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1369 - mae: 0.1369 - mse: 0.0346 - val_loss: 0.8551 - val_mae: 0.8551 - val_mse: 1.6613\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1373 - mae: 0.1373 - mse: 0.0353 - val_loss: 0.8388 - val_mae: 0.8388 - val_mse: 1.5899\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1403 - mae: 0.1403 - mse: 0.0362 - val_loss: 0.8531 - val_mae: 0.8531 - val_mse: 1.6684\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1349 - mae: 0.1349 - mse: 0.0334 - val_loss: 0.9999 - val_mae: 0.9999 - val_mse: 2.0923\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1337 - mae: 0.1337 - mse: 0.0329 - val_loss: 0.8103 - val_mae: 0.8103 - val_mse: 1.5484\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1396 - mae: 0.1396 - mse: 0.0358 - val_loss: 0.9315 - val_mae: 0.9315 - val_mse: 1.8912\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1418 - mae: 0.1418 - mse: 0.0351 - val_loss: 1.0421 - val_mae: 1.0421 - val_mse: 2.2176\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1361 - mae: 0.1361 - mse: 0.0335 - val_loss: 0.8503 - val_mae: 0.8503 - val_mse: 1.6591\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1343 - mae: 0.1343 - mse: 0.0338 - val_loss: 0.9069 - val_mae: 0.9069 - val_mse: 1.8185\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1337 - mae: 0.1337 - mse: 0.0327 - val_loss: 0.9868 - val_mae: 0.9868 - val_mse: 2.0579\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1347 - mae: 0.1347 - mse: 0.0334 - val_loss: 0.8599 - val_mae: 0.8599 - val_mse: 1.6853\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1352 - mae: 0.1352 - mse: 0.0338 - val_loss: 0.9249 - val_mae: 0.9249 - val_mse: 1.8702\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1347 - mae: 0.1347 - mse: 0.0333 - val_loss: 0.9813 - val_mae: 0.9813 - val_mse: 2.0421\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1369 - mae: 0.1369 - mse: 0.0340 - val_loss: 0.8966 - val_mae: 0.8966 - val_mse: 1.7941\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1365 - mae: 0.1365 - mse: 0.0343 - val_loss: 0.8377 - val_mae: 0.8377 - val_mse: 1.6187\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1337 - mae: 0.1337 - mse: 0.0331 - val_loss: 0.9677 - val_mae: 0.9677 - val_mse: 1.9962\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1427 - mae: 0.1427 - mse: 0.0368 - val_loss: 0.8791 - val_mae: 0.8791 - val_mse: 1.7159\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1377 - mae: 0.1377 - mse: 0.0343 - val_loss: 0.8754 - val_mae: 0.8754 - val_mse: 1.7325\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1378 - mae: 0.1378 - mse: 0.0339 - val_loss: 0.9631 - val_mae: 0.9631 - val_mse: 1.9851\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1340 - mae: 0.1340 - mse: 0.0329 - val_loss: 0.8690 - val_mae: 0.8690 - val_mse: 1.7133\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1366 - mae: 0.1366 - mse: 0.0336 - val_loss: 0.9531 - val_mae: 0.9531 - val_mse: 1.9525\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1361 - mae: 0.1361 - mse: 0.0338 - val_loss: 0.9205 - val_mae: 0.9205 - val_mse: 1.8722\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1329 - mae: 0.1329 - mse: 0.0326 - val_loss: 0.8970 - val_mae: 0.8970 - val_mse: 1.7829\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1346 - mae: 0.1346 - mse: 0.0333 - val_loss: 0.8885 - val_mae: 0.8885 - val_mse: 1.7660\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1321 - mae: 0.1321 - mse: 0.0324 - val_loss: 0.9115 - val_mae: 0.9115 - val_mse: 1.8319\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1320 - mae: 0.1320 - mse: 0.0323 - val_loss: 0.9146 - val_mae: 0.9146 - val_mse: 1.8450\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1312 - mae: 0.1312 - mse: 0.0323 - val_loss: 0.9049 - val_mae: 0.9049 - val_mse: 1.8273\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1334 - mae: 0.1334 - mse: 0.0331 - val_loss: 0.9687 - val_mae: 0.9687 - val_mse: 2.0121\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1335 - mae: 0.1335 - mse: 0.0327 - val_loss: 0.9717 - val_mae: 0.9717 - val_mse: 2.0225\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1326 - mae: 0.1326 - mse: 0.0328 - val_loss: 0.8614 - val_mae: 0.8614 - val_mse: 1.7008\n",
      "-1.9690539807725809\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "# LSTM\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D,Activation,Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "def R2(pred, true):\n",
    "    return 1 - (np.sum((true-pred)**2)) / (np.sum((true-true.mean())**2))\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = tf.keras.initializers.get('glorot_uniform')\n",
    "        # W_regularizer: 权重上的正则化\n",
    "        # b_regularizer: 偏置项的正则化\n",
    "        self.W_regularizer = tf.keras.regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = tf.keras.regularizers.get(b_regularizer)\n",
    "        # W_constraint: 权重上的约束项\n",
    "        # b_constraint: 偏置上的约束项\n",
    "        self.W_constraint = tf.keras.constraints.get(W_constraint)\n",
    "        self.b_constraint = tf.keras.constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        \n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        \n",
    "        if self.bias:\n",
    "                    self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "            \n",
    "        self.built = True\n",
    "        \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "        \n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                              K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "        \n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "            \n",
    "        eij = K.tanh(eij)\n",
    "        \n",
    "        a = K.exp(eij)\n",
    "        \n",
    "        '''\n",
    "        keras.backend.cast(x, dtype): 将张量转换到不同的 dtype 并返回\n",
    "        '''\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "            \n",
    "        '''\n",
    "        keras.backend.epsilon(): 返回浮点数\n",
    "        '''\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon()   , K.floatx())\n",
    "        \n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim\n",
    "\n",
    "class CustomEarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomEarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"val_loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            print(\"learning_rate: \",self.learning_rate)\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# print(y_valid)\n",
    "\n",
    "# LSTM 参数: return_sequences=True LSTM输出为一个序列。默认为False，输出一个值。\n",
    "# input_dim： 输入单个样本特征值的维度\n",
    "# input_length： 输入的时间点长度\n",
    "model = Sequential()\n",
    "# model.add(Conv1D(filters=64,kernel_size=1,activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(MaxPooling1D(1))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(LSTM(units=64, return_sequences=True, input_dim=x_train.shape[-1], input_length=x_train.shape[1],activation='tanh'))\n",
    "# model.add(keras.layers.Bidirectional(LSTM(units=64,return_sequences=False,activation='tanh')))\n",
    "model.add(keras.layers.LSTM(units=64,return_sequences=False,activation='tanh'))\n",
    "# model.add(Attention(5))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "EStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=25,\n",
    "                                         verbose=0,mode='min',baseline=None,\n",
    "                                         restore_best_weights=True)\n",
    "Learn_rate_adjust = tf.keras.callbacks.LearningRateScheduler(scheduler) \n",
    "callbacks_list = [\n",
    "    # 目标指标不再有改善了，就可以提前终止\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=25,\n",
    "                                         verbose=0,mode='min',baseline=None,\n",
    "                                         restore_best_weights=True),\n",
    "    # 保存模型\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'test.h5', # 文件路径\n",
    "    monitor='val_loss', # 如果val_loss 没有改善就不覆盖\n",
    "    save_best_only=True) # 保持最佳模型\n",
    "    \n",
    "]\n",
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=x_train.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "# optimizer_ad = AdamWarmup(total_steps, warmup_steps, learning_rate=1e-3, min_lr=1e-7)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=keras.losses.MAE, optimizer=adam, metrics=[\"mae\",\"mse\"])\n",
    "hist = model.fit(x_train, y_train, \n",
    "                 epochs=epochs,validation_data=(x_valid, y_valid), \n",
    "                 batch_size=batch_size, verbose=1,\n",
    "                callbacks=[callbacks_list])\n",
    "# loss= model.evaluate(x_valid, u, verbose=0)\n",
    "# print(\"loss\",loss)\n",
    "\n",
    "new_model = tf.keras.models.load_model('test.h5')\n",
    "print(y_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "042be8d4",
   "metadata": {
    "code_folding": [
     16,
     93,
     124
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 0.1286 - mae: 0.1286 - mse: 0.0909 - val_loss: 0.0417 - val_mae: 0.0417 - val_mse: 0.0030\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0286 - mae: 0.0286 - mse: 0.0024 - val_loss: 0.0385 - val_mae: 0.0385 - val_mse: 0.0025\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0277 - mae: 0.0277 - mse: 0.0022 - val_loss: 0.0284 - val_mae: 0.0284 - val_mse: 0.0015\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0272 - mae: 0.0272 - mse: 0.0020 - val_loss: 0.0390 - val_mae: 0.0390 - val_mse: 0.0023\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0275 - mae: 0.0275 - mse: 0.0020 - val_loss: 0.0475 - val_mae: 0.0475 - val_mse: 0.0040\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0271 - mae: 0.0271 - mse: 0.0021 - val_loss: 0.0262 - val_mae: 0.0262 - val_mse: 0.0018\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0265 - mae: 0.0265 - mse: 0.0020 - val_loss: 0.0251 - val_mae: 0.0251 - val_mse: 0.0013\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0265 - mae: 0.0265 - mse: 0.0020 - val_loss: 0.0605 - val_mae: 0.0605 - val_mse: 0.0050\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0269 - mae: 0.0269 - mse: 0.0021 - val_loss: 0.0297 - val_mae: 0.0297 - val_mse: 0.0018\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0265 - mae: 0.0265 - mse: 0.0019 - val_loss: 0.0234 - val_mae: 0.0234 - val_mse: 0.0013\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0261 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.0285 - val_mae: 0.0285 - val_mse: 0.0015\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0267 - mae: 0.0267 - mse: 0.0021 - val_loss: 0.0330 - val_mae: 0.0330 - val_mse: 0.0017\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0268 - mae: 0.0268 - mse: 0.0021 - val_loss: 0.0265 - val_mae: 0.0265 - val_mse: 0.0013\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0261 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.0336 - val_mae: 0.0336 - val_mse: 0.0021\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0264 - mae: 0.0264 - mse: 0.0019 - val_loss: 0.0232 - val_mae: 0.0232 - val_mse: 0.0012\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0269 - mae: 0.0269 - mse: 0.0020 - val_loss: 0.0242 - val_mae: 0.0242 - val_mse: 0.0012\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.0252 - val_mae: 0.0252 - val_mse: 0.0013\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0261 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.0280 - val_mae: 0.0280 - val_mse: 0.0014\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0270 - mae: 0.0270 - mse: 0.0019 - val_loss: 0.0239 - val_mae: 0.0239 - val_mse: 0.0012\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0019 - val_loss: 0.0237 - val_mae: 0.0237 - val_mse: 0.0012\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0255 - mae: 0.0255 - mse: 0.0018 - val_loss: 0.0300 - val_mae: 0.0300 - val_mse: 0.0016\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0256 - mae: 0.0256 - mse: 0.0018 - val_loss: 0.0224 - val_mae: 0.0224 - val_mse: 0.0011\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0282 - val_mae: 0.0282 - val_mse: 0.0016\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0227 - val_mae: 0.0227 - val_mse: 0.0011\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0256 - mae: 0.0256 - mse: 0.0018 - val_loss: 0.0326 - val_mae: 0.0326 - val_mse: 0.0021\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0257 - mae: 0.0257 - mse: 0.0018 - val_loss: 0.0245 - val_mae: 0.0245 - val_mse: 0.0012\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0448 - val_mae: 0.0448 - val_mse: 0.0032\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0019 - val_loss: 0.0240 - val_mae: 0.0240 - val_mse: 0.0012\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0017 - val_loss: 0.0314 - val_mae: 0.0314 - val_mse: 0.0017\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0250 - mae: 0.0250 - mse: 0.0018 - val_loss: 0.0243 - val_mae: 0.0243 - val_mse: 0.0013\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0258 - mae: 0.0258 - mse: 0.0018 - val_loss: 0.0238 - val_mae: 0.0238 - val_mse: 0.0011\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0264 - val_mae: 0.0264 - val_mse: 0.0013\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0018 - val_loss: 0.0228 - val_mae: 0.0228 - val_mse: 0.0011\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0013\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0266 - mae: 0.0266 - mse: 0.0019 - val_loss: 0.0329 - val_mae: 0.0329 - val_mse: 0.0019\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0245 - mae: 0.0245 - mse: 0.0018 - val_loss: 0.0229 - val_mae: 0.0229 - val_mse: 0.0011\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0018 - val_loss: 0.0266 - val_mae: 0.0266 - val_mse: 0.0014\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0017 - val_loss: 0.0270 - val_mae: 0.0270 - val_mse: 0.0013\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0238 - val_mae: 0.0238 - val_mse: 0.0012\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0017 - val_loss: 0.0246 - val_mae: 0.0246 - val_mse: 0.0013\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0270 - val_mae: 0.0270 - val_mse: 0.0015\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0235 - val_mae: 0.0235 - val_mse: 0.0012\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0017 - val_loss: 0.0227 - val_mae: 0.0227 - val_mse: 0.0011\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0286 - val_mae: 0.0286 - val_mse: 0.0014\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0237 - val_mae: 0.0237 - val_mse: 0.0011\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0245 - mae: 0.0245 - mse: 0.0017 - val_loss: 0.0231 - val_mae: 0.0231 - val_mse: 0.0011\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0221 - val_mae: 0.0221 - val_mse: 0.0011\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0372 - val_mae: 0.0372 - val_mse: 0.0023\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0226 - val_mae: 0.0226 - val_mse: 0.0011\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0244 - mae: 0.0244 - mse: 0.0017 - val_loss: 0.0254 - val_mae: 0.0254 - val_mse: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0245 - val_mae: 0.0245 - val_mse: 0.0011\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0245 - mae: 0.0245 - mse: 0.0017 - val_loss: 0.0304 - val_mae: 0.0304 - val_mse: 0.0015\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0369 - val_mae: 0.0369 - val_mse: 0.0023\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0244 - mae: 0.0244 - mse: 0.0017 - val_loss: 0.0239 - val_mae: 0.0239 - val_mse: 0.0012\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0256 - mae: 0.0256 - mse: 0.0017 - val_loss: 0.0301 - val_mae: 0.0301 - val_mse: 0.0017\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0309 - val_mae: 0.0309 - val_mse: 0.0017\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0289 - val_mae: 0.0289 - val_mse: 0.0015\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0300 - val_mae: 0.0300 - val_mse: 0.0016\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0260 - val_mae: 0.0260 - val_mse: 0.0013\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0250 - val_mae: 0.0250 - val_mse: 0.0013\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0012\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0227 - val_mae: 0.0227 - val_mse: 0.0011\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0240 - mae: 0.0240 - mse: 0.0016 - val_loss: 0.0226 - val_mae: 0.0226 - val_mse: 0.0011\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0018 - val_loss: 0.0293 - val_mae: 0.0293 - val_mse: 0.0016\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0224 - val_mae: 0.0224 - val_mse: 0.0011\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0243 - val_mae: 0.0243 - val_mse: 0.0012\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0240 - mae: 0.0240 - mse: 0.0016 - val_loss: 0.0231 - val_mae: 0.0231 - val_mse: 0.0011\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0241 - val_mae: 0.0241 - val_mse: 0.0012\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.0250 - mae: 0.0250 - mse: 0.0017 - val_loss: 0.0228 - val_mae: 0.0228 - val_mse: 0.0011\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0247 - val_mae: 0.0247 - val_mse: 0.0013\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0239 - mae: 0.0239 - mse: 0.0016 - val_loss: 0.0230 - val_mae: 0.0230 - val_mse: 0.0011\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0241 - mae: 0.0241 - mse: 0.0016 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0012\n",
      "1.1321122717955234\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "# BiLSTM\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D,Activation,Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "def R2(pred, true):\n",
    "    return 1 - (np.sum((true-pred)**2)) / (np.sum((true-true.mean())**2))\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = tf.keras.initializers.get('glorot_uniform')\n",
    "        # W_regularizer: 权重上的正则化\n",
    "        # b_regularizer: 偏置项的正则化\n",
    "        self.W_regularizer = tf.keras.regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = tf.keras.regularizers.get(b_regularizer)\n",
    "        # W_constraint: 权重上的约束项\n",
    "        # b_constraint: 偏置上的约束项\n",
    "        self.W_constraint = tf.keras.constraints.get(W_constraint)\n",
    "        self.b_constraint = tf.keras.constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        \n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        \n",
    "        if self.bias:\n",
    "                    self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "            \n",
    "        self.built = True\n",
    "        \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "        \n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                              K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "        \n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "            \n",
    "        eij = K.tanh(eij)\n",
    "        \n",
    "        a = K.exp(eij)\n",
    "        \n",
    "        '''\n",
    "        keras.backend.cast(x, dtype): 将张量转换到不同的 dtype 并返回\n",
    "        '''\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "            \n",
    "        '''\n",
    "        keras.backend.epsilon(): 返回浮点数\n",
    "        '''\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon()   , K.floatx())\n",
    "        \n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim\n",
    "\n",
    "class CustomEarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomEarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"val_loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            print(\"learning_rate: \",self.learning_rate)\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# print(y_valid)\n",
    "\n",
    "# LSTM 参数: return_sequences=True LSTM输出为一个序列。默认为False，输出一个值。\n",
    "# input_dim： 输入单个样本特征值的维度\n",
    "# input_length： 输入的时间点长度\n",
    "model = Sequential()\n",
    "# model.add(Conv1D(filters=64,kernel_size=1,activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(MaxPooling1D(1))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(LSTM(units=64, return_sequences=True, input_dim=x_train.shape[-1], input_length=x_train.shape[1],activation='tanh'))\n",
    "model.add(keras.layers.Bidirectional(LSTM(units=64,return_sequences=False,activation='tanh')))\n",
    "# model.add(keras.layers.LSTM(units=64,return_sequences=False,activation='tanh'))\n",
    "# model.add(Attention(5))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "EStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=25,\n",
    "                                         verbose=0,mode='min',baseline=None,\n",
    "                                         restore_best_weights=True)\n",
    "Learn_rate_adjust = tf.keras.callbacks.LearningRateScheduler(scheduler) \n",
    "callbacks_list = [\n",
    "    # 目标指标不再有改善了，就可以提前终止\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=25,\n",
    "                                         verbose=0,mode='min',baseline=None,\n",
    "                                         restore_best_weights=True),\n",
    "    # 保存模型\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'test.h5', # 文件路径\n",
    "    monitor='val_loss', # 如果val_loss 没有改善就不覆盖\n",
    "    save_best_only=True) # 保持最佳模型\n",
    "    \n",
    "]\n",
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=x_train.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "optimizer_ad = AdamWarmup(total_steps, warmup_steps, learning_rate=1e-3, min_lr=1e-7)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=keras.losses.MAE, optimizer=adam, metrics=[\"mae\",\"mse\"])\n",
    "hist = model.fit(x_train, y_train, \n",
    "                 epochs=epochs,validation_data=(x_valid, y_valid), \n",
    "                 batch_size=batch_size, verbose=1,\n",
    "                callbacks=[callbacks_list])\n",
    "# loss= model.evaluate(x_valid, u, verbose=0)\n",
    "# print(\"loss\",loss)\n",
    "\n",
    "new_model = tf.keras.models.load_model('test.h5')\n",
    "print(y_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e772c649",
   "metadata": {
    "code_folding": [
     16,
     93,
     124
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "96/96 [==============================] - 3s 16ms/step - loss: 0.1076 - mae: 0.1076 - mse: 0.0684 - val_loss: 0.0412 - val_mae: 0.0412 - val_mse: 0.0040\n",
      "Epoch 2/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0299 - mae: 0.0299 - mse: 0.0026 - val_loss: 0.0469 - val_mae: 0.0469 - val_mse: 0.0030\n",
      "Epoch 3/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0294 - mae: 0.0294 - mse: 0.0024 - val_loss: 0.0368 - val_mae: 0.0368 - val_mse: 0.0022\n",
      "Epoch 4/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0281 - mae: 0.0281 - mse: 0.0023 - val_loss: 0.0261 - val_mae: 0.0261 - val_mse: 0.0014\n",
      "Epoch 5/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0279 - mae: 0.0279 - mse: 0.0022 - val_loss: 0.0309 - val_mae: 0.0309 - val_mse: 0.0017\n",
      "Epoch 6/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0274 - mae: 0.0274 - mse: 0.0020 - val_loss: 0.0477 - val_mae: 0.0477 - val_mse: 0.0033\n",
      "Epoch 7/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0284 - mae: 0.0284 - mse: 0.0022 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0014\n",
      "Epoch 8/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0292 - mae: 0.0292 - mse: 0.0025 - val_loss: 0.0356 - val_mae: 0.0356 - val_mse: 0.0025\n",
      "Epoch 9/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0269 - mae: 0.0269 - mse: 0.0021 - val_loss: 0.0502 - val_mae: 0.0502 - val_mse: 0.0033\n",
      "Epoch 10/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0269 - mae: 0.0269 - mse: 0.0020 - val_loss: 0.0287 - val_mae: 0.0287 - val_mse: 0.0017\n",
      "Epoch 11/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0293 - mae: 0.0293 - mse: 0.0024 - val_loss: 0.0266 - val_mae: 0.0266 - val_mse: 0.0016\n",
      "Epoch 12/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0263 - mae: 0.0263 - mse: 0.0020 - val_loss: 0.0351 - val_mae: 0.0351 - val_mse: 0.0024\n",
      "Epoch 13/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0258 - mae: 0.0258 - mse: 0.0019 - val_loss: 0.0272 - val_mae: 0.0272 - val_mse: 0.0016\n",
      "Epoch 14/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0270 - mae: 0.0270 - mse: 0.0021 - val_loss: 0.0250 - val_mae: 0.0250 - val_mse: 0.0013\n",
      "Epoch 15/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0267 - mae: 0.0267 - mse: 0.0021 - val_loss: 0.0449 - val_mae: 0.0449 - val_mse: 0.0033\n",
      "Epoch 16/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0269 - mae: 0.0269 - mse: 0.0020 - val_loss: 0.0269 - val_mae: 0.0269 - val_mse: 0.0013\n",
      "Epoch 17/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0258 - mae: 0.0258 - mse: 0.0018 - val_loss: 0.0398 - val_mae: 0.0398 - val_mse: 0.0022\n",
      "Epoch 18/150\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0287 - mae: 0.0287 - mse: 0.0023 - val_loss: 0.0406 - val_mae: 0.0406 - val_mse: 0.0023\n",
      "Epoch 19/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0019 - val_loss: 0.0371 - val_mae: 0.0371 - val_mse: 0.0025\n",
      "Epoch 20/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0258 - mae: 0.0258 - mse: 0.0019 - val_loss: 0.0282 - val_mae: 0.0282 - val_mse: 0.0014\n",
      "Epoch 21/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.0229 - val_mae: 0.0229 - val_mse: 0.0011\n",
      "Epoch 22/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0268 - mae: 0.0268 - mse: 0.0020 - val_loss: 0.0239 - val_mae: 0.0239 - val_mse: 0.0011\n",
      "Epoch 23/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0019 - val_loss: 0.0263 - val_mae: 0.0263 - val_mse: 0.0014\n",
      "Epoch 24/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0266 - mae: 0.0266 - mse: 0.0020 - val_loss: 0.0230 - val_mae: 0.0230 - val_mse: 0.0011\n",
      "Epoch 25/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0266 - mae: 0.0266 - mse: 0.0020 - val_loss: 0.0270 - val_mae: 0.0270 - val_mse: 0.0013\n",
      "Epoch 26/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0019 - val_loss: 0.0258 - val_mae: 0.0258 - val_mse: 0.0013\n",
      "Epoch 27/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0256 - mae: 0.0256 - mse: 0.0019 - val_loss: 0.0241 - val_mae: 0.0241 - val_mse: 0.0012\n",
      "Epoch 28/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0258 - mae: 0.0258 - mse: 0.0019 - val_loss: 0.0239 - val_mae: 0.0239 - val_mse: 0.0012\n",
      "Epoch 29/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0019 - val_loss: 0.0258 - val_mae: 0.0258 - val_mse: 0.0014\n",
      "Epoch 30/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0257 - mae: 0.0257 - mse: 0.0019 - val_loss: 0.0239 - val_mae: 0.0239 - val_mse: 0.0012\n",
      "Epoch 31/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0258 - mae: 0.0258 - mse: 0.0019 - val_loss: 0.0232 - val_mae: 0.0232 - val_mse: 0.0011\n",
      "Epoch 32/150\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0018 - val_loss: 0.0252 - val_mae: 0.0252 - val_mse: 0.0013\n",
      "Epoch 33/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0234 - val_mae: 0.0234 - val_mse: 0.0011\n",
      "Epoch 34/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0268 - mae: 0.0268 - mse: 0.0019 - val_loss: 0.0363 - val_mae: 0.0363 - val_mse: 0.0019\n",
      "Epoch 35/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.0295 - val_mae: 0.0295 - val_mse: 0.0015\n",
      "Epoch 36/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0265 - mae: 0.0265 - mse: 0.0020 - val_loss: 0.0397 - val_mae: 0.0397 - val_mse: 0.0022\n",
      "Epoch 37/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0258 - mae: 0.0258 - mse: 0.0018 - val_loss: 0.0227 - val_mae: 0.0227 - val_mse: 0.0011\n",
      "Epoch 38/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0260 - val_mae: 0.0260 - val_mse: 0.0014\n",
      "Epoch 39/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0255 - mae: 0.0255 - mse: 0.0019 - val_loss: 0.0347 - val_mae: 0.0347 - val_mse: 0.0020\n",
      "Epoch 40/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0244 - mae: 0.0244 - mse: 0.0017 - val_loss: 0.0328 - val_mae: 0.0328 - val_mse: 0.0016\n",
      "Epoch 41/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0272 - val_mae: 0.0272 - val_mse: 0.0014\n",
      "Epoch 42/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0018 - val_loss: 0.0242 - val_mae: 0.0242 - val_mse: 0.0012\n",
      "Epoch 43/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0257 - mae: 0.0257 - mse: 0.0018 - val_loss: 0.0234 - val_mae: 0.0234 - val_mse: 0.0010\n",
      "Epoch 44/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0250 - mae: 0.0250 - mse: 0.0017 - val_loss: 0.0293 - val_mae: 0.0293 - val_mse: 0.0014\n",
      "Epoch 45/150\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0018 - val_loss: 0.0250 - val_mae: 0.0250 - val_mse: 0.0014\n",
      "Epoch 46/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0257 - mae: 0.0257 - mse: 0.0018 - val_loss: 0.0246 - val_mae: 0.0246 - val_mse: 0.0012\n",
      "Epoch 47/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0439 - val_mae: 0.0439 - val_mse: 0.0028\n",
      "Epoch 48/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0264 - mae: 0.0264 - mse: 0.0020 - val_loss: 0.0413 - val_mae: 0.0413 - val_mse: 0.0025\n",
      "Epoch 49/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0245 - mae: 0.0245 - mse: 0.0017 - val_loss: 0.0250 - val_mae: 0.0250 - val_mse: 0.0014\n",
      "Epoch 50/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0262 - mae: 0.0262 - mse: 0.0019 - val_loss: 0.0299 - val_mae: 0.0299 - val_mse: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0267 - mae: 0.0267 - mse: 0.0019 - val_loss: 0.0247 - val_mae: 0.0247 - val_mse: 0.0012\n",
      "Epoch 52/150\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0018 - val_loss: 0.0332 - val_mae: 0.0332 - val_mse: 0.0018\n",
      "Epoch 53/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0265 - val_mae: 0.0265 - val_mse: 0.0014\n",
      "Epoch 54/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0256 - mae: 0.0256 - mse: 0.0019 - val_loss: 0.0234 - val_mae: 0.0234 - val_mse: 0.0011\n",
      "Epoch 55/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0262 - mae: 0.0262 - mse: 0.0020 - val_loss: 0.0256 - val_mae: 0.0256 - val_mse: 0.0012\n",
      "Epoch 56/150\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0234 - val_mae: 0.0234 - val_mse: 0.0011\n",
      "Epoch 57/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0231 - val_mae: 0.0231 - val_mse: 0.0011\n",
      "Epoch 58/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0255 - mae: 0.0255 - mse: 0.0018 - val_loss: 0.0273 - val_mae: 0.0273 - val_mse: 0.0015\n",
      "Epoch 59/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0229 - val_mae: 0.0229 - val_mse: 0.0011\n",
      "Epoch 60/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0253 - val_mae: 0.0253 - val_mse: 0.0012\n",
      "Epoch 61/150\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0241 - val_mae: 0.0241 - val_mse: 0.0012\n",
      "Epoch 62/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0016 - val_loss: 0.0251 - val_mae: 0.0251 - val_mse: 0.0014\n",
      "Epoch 63/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0303 - val_mae: 0.0303 - val_mse: 0.0017\n",
      "Epoch 64/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0350 - val_mae: 0.0350 - val_mse: 0.0019\n",
      "Epoch 65/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0279 - val_mae: 0.0279 - val_mse: 0.0015\n",
      "Epoch 66/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0292 - val_mae: 0.0292 - val_mse: 0.0016\n",
      "Epoch 67/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0239 - mae: 0.0239 - mse: 0.0017 - val_loss: 0.0230 - val_mae: 0.0230 - val_mse: 0.0011\n",
      "Epoch 68/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0274 - val_mae: 0.0274 - val_mse: 0.0014\n",
      "Epoch 69/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0018 - val_loss: 0.0251 - val_mae: 0.0251 - val_mse: 0.0012\n",
      "Epoch 70/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0229 - val_mae: 0.0229 - val_mse: 0.0011\n",
      "Epoch 71/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0018 - val_loss: 0.0257 - val_mae: 0.0257 - val_mse: 0.0012\n",
      "Epoch 72/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0018 - val_loss: 0.0240 - val_mae: 0.0240 - val_mse: 0.0012\n",
      "Epoch 73/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0241 - mae: 0.0241 - mse: 0.0017 - val_loss: 0.0261 - val_mae: 0.0261 - val_mse: 0.0014\n",
      "Epoch 74/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0272 - val_mae: 0.0272 - val_mse: 0.0013\n",
      "Epoch 75/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0234 - mae: 0.0234 - mse: 0.0016 - val_loss: 0.0244 - val_mae: 0.0244 - val_mse: 0.0012\n",
      "Epoch 76/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0013\n",
      "Epoch 77/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0017 - val_loss: 0.0249 - val_mae: 0.0249 - val_mse: 0.0014\n",
      "Epoch 78/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0017 - val_loss: 0.0230 - val_mae: 0.0230 - val_mse: 0.0011\n",
      "Epoch 79/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0244 - mae: 0.0244 - mse: 0.0017 - val_loss: 0.0275 - val_mae: 0.0275 - val_mse: 0.0013\n",
      "Epoch 80/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0423 - val_mae: 0.0423 - val_mse: 0.0028\n",
      "Epoch 81/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0294 - val_mae: 0.0294 - val_mse: 0.0015\n",
      "Epoch 82/150\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.0250 - mae: 0.0250 - mse: 0.0017 - val_loss: 0.0307 - val_mae: 0.0307 - val_mse: 0.0015\n",
      "Epoch 83/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0017 - val_loss: 0.0360 - val_mae: 0.0360 - val_mse: 0.0022\n",
      "Epoch 84/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0245 - mae: 0.0245 - mse: 0.0017 - val_loss: 0.0290 - val_mae: 0.0290 - val_mse: 0.0016\n",
      "Epoch 85/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0236 - val_mae: 0.0236 - val_mse: 0.0011\n",
      "Epoch 86/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0239 - mae: 0.0239 - mse: 0.0016 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0011\n",
      "Epoch 87/150\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0316 - val_mae: 0.0316 - val_mse: 0.0018\n",
      "1.1321122717955234\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "# CNN-LSTM\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D,Activation,Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "def R2(pred, true):\n",
    "    return 1 - (np.sum((true-pred)**2)) / (np.sum((true-true.mean())**2))\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = tf.keras.initializers.get('glorot_uniform')\n",
    "        # W_regularizer: 权重上的正则化\n",
    "        # b_regularizer: 偏置项的正则化\n",
    "        self.W_regularizer = tf.keras.regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = tf.keras.regularizers.get(b_regularizer)\n",
    "        # W_constraint: 权重上的约束项\n",
    "        # b_constraint: 偏置上的约束项\n",
    "        self.W_constraint = tf.keras.constraints.get(W_constraint)\n",
    "        self.b_constraint = tf.keras.constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        \n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        \n",
    "        if self.bias:\n",
    "                    self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "            \n",
    "        self.built = True\n",
    "        \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "        \n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                              K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "        \n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "            \n",
    "        eij = K.tanh(eij)\n",
    "        \n",
    "        a = K.exp(eij)\n",
    "        \n",
    "        '''\n",
    "        keras.backend.cast(x, dtype): 将张量转换到不同的 dtype 并返回\n",
    "        '''\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "            \n",
    "        '''\n",
    "        keras.backend.epsilon(): 返回浮点数\n",
    "        '''\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon()   , K.floatx())\n",
    "        \n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim\n",
    "\n",
    "class CustomEarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomEarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"val_loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            print(\"learning_rate: \",self.learning_rate)\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# print(y_valid)\n",
    "# LSTM 参数: return_sequences=True LSTM输出为一个序列。默认为False，输出一个值。\n",
    "# input_dim： 输入单个样本特征值的维度\n",
    "# input_length： 输入的时间点长度\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64,kernel_size=1,activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(1))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(LSTM(units=64, return_sequences=True, input_dim=x_train.shape[-1], input_length=x_train.shape[1],activation='tanh'))\n",
    "# model.add(keras.layers.Bidirectional(LSTM(units=64,return_sequences=False,activation='tanh')))\n",
    "model.add(keras.layers.LSTM(units=64,return_sequences=False,activation='tanh'))\n",
    "# model.add(Attention(5))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "EStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=50,\n",
    "                                         verbose=0,mode='min',baseline=None,\n",
    "                                         restore_best_weights=True)\n",
    "Learn_rate_adjust = tf.keras.callbacks.LearningRateScheduler(scheduler) \n",
    "\n",
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=x_train.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "optimizer_ad = AdamWarmup(total_steps, warmup_steps, learning_rate=1e-3, min_lr=1e-7)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=keras.losses.MAE, optimizer=adam, metrics=[\"mae\",\"mse\"])\n",
    "hist = model.fit(x_train, y_train, \n",
    "                 epochs=epochs,validation_data=(x_valid, y_valid), \n",
    "                 batch_size=batch_size, verbose=1,\n",
    "                callbacks=[EStop])\n",
    "# loss= model.evaluate(x_valid, u, verbose=0)\n",
    "# print(\"loss\",loss)\n",
    "\n",
    "\n",
    "print(y_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "170e372b",
   "metadata": {
    "code_folding": [
     16,
     93,
     124
    ],
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "96/96 [==============================] - 5s 21ms/step - loss: 0.0793 - mae: 0.0793 - mse: 0.0352 - val_loss: 0.0400 - val_mae: 0.0400 - val_mse: 0.0031\n",
      "Epoch 2/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0299 - mae: 0.0299 - mse: 0.0027 - val_loss: 0.0384 - val_mae: 0.0384 - val_mse: 0.0024\n",
      "Epoch 3/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0303 - mae: 0.0303 - mse: 0.0025 - val_loss: 0.0424 - val_mae: 0.0424 - val_mse: 0.0027\n",
      "Epoch 4/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0297 - mae: 0.0297 - mse: 0.0025 - val_loss: 0.0252 - val_mae: 0.0252 - val_mse: 0.0014\n",
      "Epoch 5/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0285 - mae: 0.0285 - mse: 0.0022 - val_loss: 0.0260 - val_mae: 0.0260 - val_mse: 0.0015\n",
      "Epoch 6/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0267 - mae: 0.0267 - mse: 0.0020 - val_loss: 0.0320 - val_mae: 0.0320 - val_mse: 0.0020\n",
      "Epoch 7/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0272 - mae: 0.0272 - mse: 0.0020 - val_loss: 0.0249 - val_mae: 0.0249 - val_mse: 0.0012\n",
      "Epoch 8/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0283 - mae: 0.0283 - mse: 0.0022 - val_loss: 0.0298 - val_mae: 0.0298 - val_mse: 0.0017\n",
      "Epoch 9/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0276 - mae: 0.0276 - mse: 0.0021 - val_loss: 0.0419 - val_mae: 0.0419 - val_mse: 0.0031\n",
      "Epoch 10/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0019 - val_loss: 0.0422 - val_mae: 0.0422 - val_mse: 0.0025\n",
      "Epoch 11/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0272 - mae: 0.0272 - mse: 0.0020 - val_loss: 0.0343 - val_mae: 0.0343 - val_mse: 0.0020\n",
      "Epoch 12/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0256 - mae: 0.0256 - mse: 0.0019 - val_loss: 0.0358 - val_mae: 0.0358 - val_mse: 0.0022\n",
      "Epoch 13/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.0239 - val_mae: 0.0239 - val_mse: 0.0011\n",
      "Epoch 14/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0261 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.0618 - val_mae: 0.0618 - val_mse: 0.0051\n",
      "Epoch 15/150\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.0406 - val_mae: 0.0406 - val_mse: 0.0025\n",
      "Epoch 16/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0280 - mae: 0.0280 - mse: 0.0022 - val_loss: 0.0235 - val_mae: 0.0235 - val_mse: 0.0012\n",
      "Epoch 17/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0018 - val_loss: 0.0244 - val_mae: 0.0244 - val_mse: 0.0013\n",
      "Epoch 18/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0331 - val_mae: 0.0331 - val_mse: 0.0018\n",
      "Epoch 19/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0261 - mae: 0.0261 - mse: 0.0020 - val_loss: 0.0230 - val_mae: 0.0230 - val_mse: 0.0011\n",
      "Epoch 20/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.0251 - val_mae: 0.0251 - val_mse: 0.0013\n",
      "Epoch 21/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.0317 - val_mae: 0.0317 - val_mse: 0.0018\n",
      "Epoch 22/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0262 - mae: 0.0262 - mse: 0.0019 - val_loss: 0.0469 - val_mae: 0.0469 - val_mse: 0.0031\n",
      "Epoch 23/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0266 - mae: 0.0266 - mse: 0.0019 - val_loss: 0.0251 - val_mae: 0.0251 - val_mse: 0.0013\n",
      "Epoch 24/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0018 - val_loss: 0.0458 - val_mae: 0.0458 - val_mse: 0.0033\n",
      "Epoch 25/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0269 - mae: 0.0269 - mse: 0.0020 - val_loss: 0.0262 - val_mae: 0.0262 - val_mse: 0.0013\n",
      "Epoch 26/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0257 - mae: 0.0257 - mse: 0.0018 - val_loss: 0.0235 - val_mae: 0.0235 - val_mse: 0.0011\n",
      "Epoch 27/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0255 - mae: 0.0255 - mse: 0.0018 - val_loss: 0.0344 - val_mae: 0.0344 - val_mse: 0.0018\n",
      "Epoch 28/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0294 - val_mae: 0.0294 - val_mse: 0.0015\n",
      "Epoch 29/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0324 - val_mae: 0.0324 - val_mse: 0.0016\n",
      "Epoch 30/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0261 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.0377 - val_mae: 0.0377 - val_mse: 0.0026\n",
      "Epoch 31/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0235 - val_mae: 0.0235 - val_mse: 0.0011\n",
      "Epoch 32/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0258 - mae: 0.0258 - mse: 0.0019 - val_loss: 0.0263 - val_mae: 0.0263 - val_mse: 0.0014\n",
      "Epoch 33/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0018 - val_loss: 0.0332 - val_mae: 0.0332 - val_mse: 0.0018\n",
      "Epoch 34/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0238 - val_mae: 0.0238 - val_mse: 0.0011\n",
      "Epoch 35/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0257 - mae: 0.0257 - mse: 0.0019 - val_loss: 0.0241 - val_mae: 0.0241 - val_mse: 0.0012\n",
      "Epoch 36/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0019 - val_loss: 0.0259 - val_mae: 0.0259 - val_mse: 0.0013\n",
      "Epoch 37/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0464 - val_mae: 0.0464 - val_mse: 0.0032\n",
      "Epoch 38/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0018 - val_loss: 0.0286 - val_mae: 0.0286 - val_mse: 0.0014\n",
      "Epoch 39/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0244 - val_mae: 0.0244 - val_mse: 0.0013\n",
      "Epoch 40/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0276 - val_mae: 0.0276 - val_mse: 0.0013\n",
      "Epoch 41/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0018 - val_loss: 0.0238 - val_mae: 0.0238 - val_mse: 0.0011\n",
      "Epoch 42/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0241 - mae: 0.0241 - mse: 0.0016 - val_loss: 0.0253 - val_mae: 0.0253 - val_mse: 0.0013\n",
      "Epoch 43/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0351 - val_mae: 0.0351 - val_mse: 0.0021\n",
      "Epoch 44/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0264 - val_mae: 0.0264 - val_mse: 0.0013\n",
      "Epoch 45/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0018 - val_loss: 0.0277 - val_mae: 0.0277 - val_mse: 0.0014\n",
      "Epoch 46/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0251 - val_mae: 0.0251 - val_mse: 0.0012\n",
      "Epoch 47/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0257 - mae: 0.0257 - mse: 0.0019 - val_loss: 0.0270 - val_mae: 0.0270 - val_mse: 0.0014\n",
      "Epoch 48/150\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0017 - val_loss: 0.0288 - val_mae: 0.0288 - val_mse: 0.0015\n",
      "Epoch 49/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0294 - val_mae: 0.0294 - val_mse: 0.0018\n",
      "Epoch 50/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0239 - val_mae: 0.0239 - val_mse: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0017 - val_loss: 0.0249 - val_mae: 0.0249 - val_mse: 0.0012\n",
      "Epoch 52/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0250 - mae: 0.0250 - mse: 0.0018 - val_loss: 0.0390 - val_mae: 0.0390 - val_mse: 0.0021\n",
      "Epoch 53/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0261 - mae: 0.0261 - mse: 0.0018 - val_loss: 0.0234 - val_mae: 0.0234 - val_mse: 0.0012\n",
      "Epoch 54/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0246 - val_mae: 0.0246 - val_mse: 0.0011\n",
      "Epoch 55/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0355 - val_mae: 0.0355 - val_mse: 0.0021\n",
      "Epoch 56/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0264 - mae: 0.0264 - mse: 0.0020 - val_loss: 0.0300 - val_mae: 0.0300 - val_mse: 0.0016\n",
      "Epoch 57/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0244 - val_mae: 0.0244 - val_mse: 0.0012\n",
      "Epoch 58/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0327 - val_mae: 0.0327 - val_mse: 0.0017\n",
      "Epoch 59/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0328 - val_mae: 0.0328 - val_mse: 0.0019\n",
      "Epoch 60/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0018 - val_loss: 0.0246 - val_mae: 0.0246 - val_mse: 0.0012\n",
      "Epoch 61/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0284 - val_mae: 0.0284 - val_mse: 0.0014\n",
      "Epoch 62/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0282 - val_mae: 0.0282 - val_mse: 0.0013\n",
      "Epoch 63/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0275 - val_mae: 0.0275 - val_mse: 0.0013\n",
      "Epoch 64/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0238 - val_mae: 0.0238 - val_mse: 0.0012\n",
      "Epoch 65/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0240 - mae: 0.0240 - mse: 0.0016 - val_loss: 0.0238 - val_mae: 0.0238 - val_mse: 0.0011\n",
      "Epoch 66/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0016 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0013\n",
      "Epoch 67/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0284 - val_mae: 0.0284 - val_mse: 0.0015\n",
      "Epoch 68/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0236 - mae: 0.0236 - mse: 0.0016 - val_loss: 0.0268 - val_mae: 0.0268 - val_mse: 0.0013\n",
      "Epoch 69/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0241 - mae: 0.0241 - mse: 0.0017 - val_loss: 0.0230 - val_mae: 0.0230 - val_mse: 0.0011\n",
      "Epoch 70/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0238 - mae: 0.0238 - mse: 0.0016 - val_loss: 0.0249 - val_mae: 0.0249 - val_mse: 0.0013\n",
      "Epoch 71/150\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0385 - val_mae: 0.0385 - val_mse: 0.0021\n",
      "Epoch 72/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0258 - val_mae: 0.0258 - val_mse: 0.0012\n",
      "Epoch 73/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0238 - mae: 0.0238 - mse: 0.0016 - val_loss: 0.0251 - val_mae: 0.0251 - val_mse: 0.0013\n",
      "Epoch 74/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0017 - val_loss: 0.0228 - val_mae: 0.0228 - val_mse: 0.0011\n",
      "Epoch 75/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0239 - mae: 0.0239 - mse: 0.0016 - val_loss: 0.0235 - val_mae: 0.0235 - val_mse: 0.0011\n",
      "Epoch 76/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0237 - mae: 0.0237 - mse: 0.0016 - val_loss: 0.0304 - val_mae: 0.0304 - val_mse: 0.0017\n",
      "Epoch 77/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0017 - val_loss: 0.0256 - val_mae: 0.0256 - val_mse: 0.0013\n",
      "Epoch 78/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0239 - mae: 0.0239 - mse: 0.0016 - val_loss: 0.0342 - val_mae: 0.0342 - val_mse: 0.0018\n",
      "Epoch 79/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0235 - mae: 0.0235 - mse: 0.0015 - val_loss: 0.0255 - val_mae: 0.0255 - val_mse: 0.0013\n",
      "Epoch 80/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0235 - mae: 0.0235 - mse: 0.0016 - val_loss: 0.0297 - val_mae: 0.0297 - val_mse: 0.0017\n",
      "Epoch 81/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0018 - val_loss: 0.0318 - val_mae: 0.0318 - val_mse: 0.0018\n",
      "Epoch 82/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0239 - mae: 0.0239 - mse: 0.0016 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0012\n",
      "Epoch 83/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0239 - mae: 0.0239 - mse: 0.0016 - val_loss: 0.0386 - val_mae: 0.0386 - val_mse: 0.0023\n",
      "Epoch 84/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0016 - val_loss: 0.0266 - val_mae: 0.0266 - val_mse: 0.0016\n",
      "Epoch 85/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0237 - mae: 0.0237 - mse: 0.0016 - val_loss: 0.0266 - val_mae: 0.0266 - val_mse: 0.0015\n",
      "Epoch 86/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0237 - mae: 0.0237 - mse: 0.0016 - val_loss: 0.0309 - val_mae: 0.0309 - val_mse: 0.0015\n",
      "Epoch 87/150\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0240 - mae: 0.0240 - mse: 0.0016 - val_loss: 0.0245 - val_mae: 0.0245 - val_mse: 0.0012\n",
      "Epoch 88/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0234 - mae: 0.0234 - mse: 0.0015 - val_loss: 0.0313 - val_mae: 0.0313 - val_mse: 0.0018\n",
      "Epoch 89/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0235 - mae: 0.0235 - mse: 0.0015 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0012\n",
      "Epoch 90/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0235 - mae: 0.0235 - mse: 0.0016 - val_loss: 0.0341 - val_mae: 0.0341 - val_mse: 0.0020\n",
      "Epoch 91/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0233 - mae: 0.0233 - mse: 0.0016 - val_loss: 0.0279 - val_mae: 0.0279 - val_mse: 0.0014\n",
      "Epoch 92/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0244 - mae: 0.0244 - mse: 0.0017 - val_loss: 0.0271 - val_mae: 0.0271 - val_mse: 0.0013\n",
      "Epoch 93/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0245 - mae: 0.0245 - mse: 0.0016 - val_loss: 0.0242 - val_mae: 0.0242 - val_mse: 0.0012\n",
      "Epoch 94/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0233 - mae: 0.0233 - mse: 0.0015 - val_loss: 0.0249 - val_mae: 0.0249 - val_mse: 0.0011\n",
      "Epoch 95/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0232 - mae: 0.0232 - mse: 0.0015 - val_loss: 0.0278 - val_mae: 0.0278 - val_mse: 0.0013\n",
      "Epoch 96/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0240 - mae: 0.0240 - mse: 0.0016 - val_loss: 0.0243 - val_mae: 0.0243 - val_mse: 0.0012\n",
      "Epoch 97/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0237 - mae: 0.0237 - mse: 0.0016 - val_loss: 0.0259 - val_mae: 0.0259 - val_mse: 0.0013\n",
      "Epoch 98/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0235 - mae: 0.0235 - mse: 0.0015 - val_loss: 0.0246 - val_mae: 0.0246 - val_mse: 0.0011\n",
      "Epoch 99/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0236 - mae: 0.0236 - mse: 0.0015 - val_loss: 0.0276 - val_mae: 0.0276 - val_mse: 0.0014\n",
      "Epoch 100/150\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0238 - mae: 0.0238 - mse: 0.0016 - val_loss: 0.0233 - val_mae: 0.0233 - val_mse: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0231 - mae: 0.0231 - mse: 0.0014 - val_loss: 0.0316 - val_mae: 0.0316 - val_mse: 0.0018\n",
      "Epoch 102/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0017 - val_loss: 0.0283 - val_mae: 0.0283 - val_mse: 0.0015\n",
      "Epoch 103/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0232 - mae: 0.0232 - mse: 0.0015 - val_loss: 0.0233 - val_mae: 0.0233 - val_mse: 0.0011\n",
      "Epoch 104/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0237 - mae: 0.0237 - mse: 0.0015 - val_loss: 0.0236 - val_mae: 0.0236 - val_mse: 0.0011\n",
      "Epoch 105/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0235 - mae: 0.0235 - mse: 0.0015 - val_loss: 0.0259 - val_mae: 0.0259 - val_mse: 0.0013\n",
      "Epoch 106/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0231 - mae: 0.0231 - mse: 0.0015 - val_loss: 0.0433 - val_mae: 0.0433 - val_mse: 0.0027\n",
      "Epoch 107/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0232 - mae: 0.0232 - mse: 0.0015 - val_loss: 0.0271 - val_mae: 0.0271 - val_mse: 0.0013\n",
      "Epoch 108/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0244 - mae: 0.0244 - mse: 0.0015 - val_loss: 0.0272 - val_mae: 0.0272 - val_mse: 0.0015\n",
      "Epoch 109/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0231 - mae: 0.0231 - mse: 0.0015 - val_loss: 0.0285 - val_mae: 0.0285 - val_mse: 0.0014\n",
      "Epoch 110/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0234 - mae: 0.0234 - mse: 0.0015 - val_loss: 0.0245 - val_mae: 0.0245 - val_mse: 0.0011\n",
      "Epoch 111/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0233 - mae: 0.0233 - mse: 0.0015 - val_loss: 0.0260 - val_mae: 0.0260 - val_mse: 0.0014\n",
      "Epoch 112/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0234 - mae: 0.0234 - mse: 0.0015 - val_loss: 0.0520 - val_mae: 0.0520 - val_mse: 0.0037\n",
      "Epoch 113/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0240 - mae: 0.0240 - mse: 0.0016 - val_loss: 0.0233 - val_mae: 0.0233 - val_mse: 0.0011\n",
      "Epoch 114/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0238 - mae: 0.0238 - mse: 0.0015 - val_loss: 0.0392 - val_mae: 0.0392 - val_mse: 0.0024\n",
      "Epoch 115/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0016 - val_loss: 0.0228 - val_mae: 0.0228 - val_mse: 0.0010\n",
      "Epoch 116/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0224 - mae: 0.0224 - mse: 0.0014 - val_loss: 0.0255 - val_mae: 0.0255 - val_mse: 0.0012\n",
      "Epoch 117/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0226 - mae: 0.0226 - mse: 0.0014 - val_loss: 0.0279 - val_mae: 0.0279 - val_mse: 0.0015\n",
      "Epoch 118/150\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0223 - mae: 0.0223 - mse: 0.0014 - val_loss: 0.0242 - val_mae: 0.0242 - val_mse: 0.0012\n",
      "Epoch 119/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0228 - mae: 0.0228 - mse: 0.0015 - val_loss: 0.0296 - val_mae: 0.0296 - val_mse: 0.0016\n",
      "Epoch 120/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0232 - mae: 0.0232 - mse: 0.0015 - val_loss: 0.0299 - val_mae: 0.0299 - val_mse: 0.0016\n",
      "Epoch 121/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0240 - mae: 0.0240 - mse: 0.0016 - val_loss: 0.0268 - val_mae: 0.0268 - val_mse: 0.0014\n",
      "Epoch 122/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0224 - mae: 0.0224 - mse: 0.0014 - val_loss: 0.0236 - val_mae: 0.0236 - val_mse: 0.0011\n",
      "Epoch 123/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0232 - mae: 0.0232 - mse: 0.0015 - val_loss: 0.0234 - val_mae: 0.0234 - val_mse: 0.0011\n",
      "Epoch 124/150\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0228 - mae: 0.0228 - mse: 0.0014 - val_loss: 0.0239 - val_mae: 0.0239 - val_mse: 0.0012\n",
      "Epoch 125/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0224 - mae: 0.0224 - mse: 0.0014 - val_loss: 0.0273 - val_mae: 0.0273 - val_mse: 0.0015\n",
      "Epoch 126/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0233 - mae: 0.0233 - mse: 0.0015 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0012\n",
      "Epoch 127/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0227 - mae: 0.0227 - mse: 0.0014 - val_loss: 0.0260 - val_mae: 0.0260 - val_mse: 0.0014\n",
      "Epoch 128/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0230 - mae: 0.0230 - mse: 0.0014 - val_loss: 0.0247 - val_mae: 0.0247 - val_mse: 0.0012\n",
      "Epoch 129/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0222 - mae: 0.0222 - mse: 0.0013 - val_loss: 0.0408 - val_mae: 0.0408 - val_mse: 0.0026\n",
      "Epoch 130/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0225 - mae: 0.0225 - mse: 0.0014 - val_loss: 0.0236 - val_mae: 0.0236 - val_mse: 0.0011\n",
      "Epoch 131/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0235 - mae: 0.0235 - mse: 0.0015 - val_loss: 0.0336 - val_mae: 0.0336 - val_mse: 0.0019\n",
      "Epoch 132/150\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0227 - mae: 0.0227 - mse: 0.0014 - val_loss: 0.0261 - val_mae: 0.0261 - val_mse: 0.0013\n",
      "Epoch 133/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0227 - mae: 0.0227 - mse: 0.0014 - val_loss: 0.0275 - val_mae: 0.0275 - val_mse: 0.0014\n",
      "Epoch 134/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0225 - mae: 0.0225 - mse: 0.0014 - val_loss: 0.0234 - val_mae: 0.0234 - val_mse: 0.0011\n",
      "Epoch 135/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0228 - mae: 0.0228 - mse: 0.0014 - val_loss: 0.0239 - val_mae: 0.0239 - val_mse: 0.0011\n",
      "Epoch 136/150\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0223 - mae: 0.0223 - mse: 0.0013 - val_loss: 0.0252 - val_mae: 0.0252 - val_mse: 0.0013\n",
      "Epoch 137/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0219 - mae: 0.0219 - mse: 0.0013 - val_loss: 0.0258 - val_mae: 0.0258 - val_mse: 0.0014\n",
      "Epoch 138/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0222 - mae: 0.0222 - mse: 0.0014 - val_loss: 0.0271 - val_mae: 0.0271 - val_mse: 0.0014\n",
      "Epoch 139/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0222 - mae: 0.0222 - mse: 0.0013 - val_loss: 0.0258 - val_mae: 0.0258 - val_mse: 0.0012\n",
      "Epoch 140/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0230 - mae: 0.0230 - mse: 0.0014 - val_loss: 0.0299 - val_mae: 0.0299 - val_mse: 0.0017\n",
      "Epoch 141/150\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0224 - mae: 0.0224 - mse: 0.0014 - val_loss: 0.0285 - val_mae: 0.0285 - val_mse: 0.0016\n",
      "Epoch 142/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0230 - mae: 0.0230 - mse: 0.0014 - val_loss: 0.0256 - val_mae: 0.0256 - val_mse: 0.0012\n",
      "Epoch 143/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0228 - mae: 0.0228 - mse: 0.0014 - val_loss: 0.0266 - val_mae: 0.0266 - val_mse: 0.0013\n",
      "Epoch 144/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0218 - mae: 0.0218 - mse: 0.0013 - val_loss: 0.0237 - val_mae: 0.0237 - val_mse: 0.0011\n",
      "Epoch 145/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0224 - mae: 0.0224 - mse: 0.0013 - val_loss: 0.0249 - val_mae: 0.0249 - val_mse: 0.0013\n",
      "Epoch 146/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0226 - mae: 0.0226 - mse: 0.0014 - val_loss: 0.0235 - val_mae: 0.0235 - val_mse: 0.0011\n",
      "Epoch 147/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0225 - mae: 0.0225 - mse: 0.0014 - val_loss: 0.0296 - val_mae: 0.0296 - val_mse: 0.0016\n",
      "Epoch 148/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0218 - mae: 0.0218 - mse: 0.0013 - val_loss: 0.0253 - val_mae: 0.0253 - val_mse: 0.0013\n",
      "Epoch 149/150\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0224 - mae: 0.0224 - mse: 0.0013 - val_loss: 0.0316 - val_mae: 0.0316 - val_mse: 0.0017\n",
      "Epoch 150/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 12ms/step - loss: 0.0218 - mae: 0.0218 - mse: 0.0013 - val_loss: 0.0246 - val_mae: 0.0246 - val_mse: 0.0013\n",
      "1.1321122717955234\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "# CNN-BiLSTM\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D,Activation,Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "def R2(pred, true):\n",
    "    return 1 - (np.sum((true-pred)**2)) / (np.sum((true-true.mean())**2))\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = tf.keras.initializers.get('glorot_uniform')\n",
    "        # W_regularizer: 权重上的正则化\n",
    "        # b_regularizer: 偏置项的正则化\n",
    "        self.W_regularizer = tf.keras.regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = tf.keras.regularizers.get(b_regularizer)\n",
    "        # W_constraint: 权重上的约束项\n",
    "        # b_constraint: 偏置上的约束项\n",
    "        self.W_constraint = tf.keras.constraints.get(W_constraint)\n",
    "        self.b_constraint = tf.keras.constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        \n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        \n",
    "        if self.bias:\n",
    "                    self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "            \n",
    "        self.built = True\n",
    "        \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "        \n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                              K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "        \n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "            \n",
    "        eij = K.tanh(eij)\n",
    "        \n",
    "        a = K.exp(eij)\n",
    "        \n",
    "        '''\n",
    "        keras.backend.cast(x, dtype): 将张量转换到不同的 dtype 并返回\n",
    "        '''\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "            \n",
    "        '''\n",
    "        keras.backend.epsilon(): 返回浮点数\n",
    "        '''\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon()   , K.floatx())\n",
    "        \n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim\n",
    "\n",
    "class CustomEarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomEarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"val_loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            print(\"learning_rate: \",self.learning_rate)\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# print(y_valid)\n",
    "# LSTM 参数: return_sequences=True LSTM输出为一个序列。默认为False，输出一个值。\n",
    "# input_dim： 输入单个样本特征值的维度\n",
    "# input_length： 输入的时间点长度\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64,kernel_size=1,activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(1))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(LSTM(units=100, return_sequences=True, input_dim=x_train.shape[-1], input_length=x_train.shape[1],activation='tanh'))\n",
    "model.add(keras.layers.Bidirectional(LSTM(units=64,return_sequences=False,activation='tanh')))\n",
    "# model.add(keras.layers.LSTM(units=64,return_sequences=True,activation='tanh'))\n",
    "# model.add(Attention(5))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "EStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=70,\n",
    "                                         verbose=0,mode='min',baseline=None,\n",
    "                                         restore_best_weights=True)\n",
    "Learn_rate_adjust = tf.keras.callbacks.LearningRateScheduler(scheduler) \n",
    "\n",
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=x_train.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "optimizer_ad = AdamWarmup(total_steps, warmup_steps, learning_rate=1e-3, min_lr=1e-7)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=keras.losses.MAE, optimizer=adam, metrics=[\"mae\",\"mse\"])\n",
    "hist = model.fit(x_train, y_train, \n",
    "                 epochs=epochs,validation_data=(x_valid, y_valid), \n",
    "                 batch_size=batch_size, verbose=1,\n",
    "                callbacks=[EStop])\n",
    "# loss= model.evaluate(x_valid, u, verbose=0)\n",
    "# print(\"loss\",loss)\n",
    "\n",
    "\n",
    "print(y_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd62dd66",
   "metadata": {
    "code_folding": [
     11,
     13,
     16,
     93,
     124
    ],
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "96/96 [==============================] - 5s 22ms/step - loss: 0.0800 - mae: 0.0800 - mse: 0.0304 - val_loss: 0.0516 - val_mae: 0.0516 - val_mse: 0.0037\n",
      "Epoch 2/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0301 - mae: 0.0301 - mse: 0.0025 - val_loss: 0.0360 - val_mae: 0.0360 - val_mse: 0.0030\n",
      "Epoch 3/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0291 - mae: 0.0291 - mse: 0.0024 - val_loss: 0.0304 - val_mae: 0.0304 - val_mse: 0.0021\n",
      "Epoch 4/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0265 - mae: 0.0265 - mse: 0.0021 - val_loss: 0.0327 - val_mae: 0.0327 - val_mse: 0.0019\n",
      "Epoch 5/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0265 - mae: 0.0265 - mse: 0.0020 - val_loss: 0.0366 - val_mae: 0.0366 - val_mse: 0.0025\n",
      "Epoch 6/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0277 - mae: 0.0277 - mse: 0.0023 - val_loss: 0.0322 - val_mae: 0.0322 - val_mse: 0.0018\n",
      "Epoch 7/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0019 - val_loss: 0.0249 - val_mae: 0.0249 - val_mse: 0.0014\n",
      "Epoch 8/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0268 - mae: 0.0268 - mse: 0.0020 - val_loss: 0.0283 - val_mae: 0.0283 - val_mse: 0.0021\n",
      "Epoch 9/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0269 - mae: 0.0269 - mse: 0.0021 - val_loss: 0.0304 - val_mae: 0.0304 - val_mse: 0.0016\n",
      "Epoch 10/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0266 - mae: 0.0266 - mse: 0.0020 - val_loss: 0.0281 - val_mae: 0.0281 - val_mse: 0.0015\n",
      "Epoch 11/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0263 - mae: 0.0263 - mse: 0.0020 - val_loss: 0.0263 - val_mae: 0.0263 - val_mse: 0.0014\n",
      "Epoch 12/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0274 - mae: 0.0274 - mse: 0.0020 - val_loss: 0.0416 - val_mae: 0.0416 - val_mse: 0.0031\n",
      "Epoch 13/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0261 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.0246 - val_mae: 0.0246 - val_mse: 0.0014\n",
      "Epoch 14/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0273 - mae: 0.0273 - mse: 0.0020 - val_loss: 0.0234 - val_mae: 0.0234 - val_mse: 0.0012\n",
      "Epoch 15/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0020 - val_loss: 0.0583 - val_mae: 0.0583 - val_mse: 0.0047\n",
      "Epoch 16/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0274 - mae: 0.0274 - mse: 0.0021 - val_loss: 0.0262 - val_mae: 0.0262 - val_mse: 0.0015\n",
      "Epoch 17/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0258 - mae: 0.0258 - mse: 0.0019 - val_loss: 0.0756 - val_mae: 0.0756 - val_mse: 0.0071\n",
      "Epoch 18/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0260 - mae: 0.0260 - mse: 0.0020 - val_loss: 0.0310 - val_mae: 0.0310 - val_mse: 0.0017\n",
      "Epoch 19/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0270 - mae: 0.0270 - mse: 0.0021 - val_loss: 0.0303 - val_mae: 0.0303 - val_mse: 0.0015\n",
      "Epoch 20/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0019 - val_loss: 0.0313 - val_mae: 0.0313 - val_mse: 0.0017\n",
      "Epoch 21/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0244 - val_mae: 0.0244 - val_mse: 0.0013\n",
      "Epoch 22/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0250 - mae: 0.0250 - mse: 0.0018 - val_loss: 0.0250 - val_mae: 0.0250 - val_mse: 0.0012\n",
      "Epoch 23/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0275 - mae: 0.0275 - mse: 0.0021 - val_loss: 0.0552 - val_mae: 0.0552 - val_mse: 0.0040\n",
      "Epoch 24/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0255 - val_mae: 0.0255 - val_mse: 0.0012\n",
      "Epoch 25/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0018 - val_loss: 0.0267 - val_mae: 0.0267 - val_mse: 0.0014\n",
      "Epoch 26/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0269 - mae: 0.0269 - mse: 0.0021 - val_loss: 0.0229 - val_mae: 0.0229 - val_mse: 0.0010\n",
      "Epoch 27/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0259 - mae: 0.0259 - mse: 0.0018 - val_loss: 0.0354 - val_mae: 0.0354 - val_mse: 0.0019\n",
      "Epoch 28/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0276 - val_mae: 0.0276 - val_mse: 0.0013\n",
      "Epoch 29/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0256 - mae: 0.0256 - mse: 0.0019 - val_loss: 0.0234 - val_mae: 0.0234 - val_mse: 0.0011\n",
      "Epoch 30/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0266 - mae: 0.0266 - mse: 0.0019 - val_loss: 0.0259 - val_mae: 0.0259 - val_mse: 0.0013\n",
      "Epoch 31/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0256 - mae: 0.0256 - mse: 0.0019 - val_loss: 0.0315 - val_mae: 0.0315 - val_mse: 0.0016\n",
      "Epoch 32/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0257 - mae: 0.0257 - mse: 0.0019 - val_loss: 0.0286 - val_mae: 0.0286 - val_mse: 0.0016\n",
      "Epoch 33/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0017 - val_loss: 0.0238 - val_mae: 0.0238 - val_mse: 0.0011\n",
      "Epoch 34/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0019 - val_loss: 0.0224 - val_mae: 0.0224 - val_mse: 0.0010\n",
      "Epoch 35/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0018 - val_loss: 0.0411 - val_mae: 0.0411 - val_mse: 0.0023\n",
      "Epoch 36/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0262 - mae: 0.0262 - mse: 0.0020 - val_loss: 0.0318 - val_mae: 0.0318 - val_mse: 0.0017\n",
      "Epoch 37/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0018 - val_loss: 0.0262 - val_mae: 0.0262 - val_mse: 0.0013\n",
      "Epoch 38/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0250 - mae: 0.0250 - mse: 0.0017 - val_loss: 0.0258 - val_mae: 0.0258 - val_mse: 0.0013\n",
      "Epoch 39/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0257 - mae: 0.0257 - mse: 0.0019 - val_loss: 0.0380 - val_mae: 0.0380 - val_mse: 0.0023\n",
      "Epoch 40/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0018 - val_loss: 0.0365 - val_mae: 0.0365 - val_mse: 0.0025\n",
      "Epoch 41/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0255 - mae: 0.0255 - mse: 0.0019 - val_loss: 0.0301 - val_mae: 0.0301 - val_mse: 0.0015\n",
      "Epoch 42/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0018 - val_loss: 0.0282 - val_mae: 0.0282 - val_mse: 0.0015\n",
      "Epoch 43/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0256 - mae: 0.0256 - mse: 0.0018 - val_loss: 0.0259 - val_mae: 0.0259 - val_mse: 0.0012\n",
      "Epoch 44/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0261 - mae: 0.0261 - mse: 0.0019 - val_loss: 0.0294 - val_mae: 0.0294 - val_mse: 0.0014\n",
      "Epoch 45/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0250 - mae: 0.0250 - mse: 0.0018 - val_loss: 0.0533 - val_mae: 0.0533 - val_mse: 0.0039\n",
      "Epoch 46/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0257 - mae: 0.0257 - mse: 0.0019 - val_loss: 0.0288 - val_mae: 0.0288 - val_mse: 0.0017\n",
      "Epoch 47/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0303 - val_mae: 0.0303 - val_mse: 0.0015\n",
      "Epoch 48/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0018 - val_loss: 0.0249 - val_mae: 0.0249 - val_mse: 0.0011\n",
      "Epoch 49/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0018 - val_loss: 0.0256 - val_mae: 0.0256 - val_mse: 0.0013\n",
      "Epoch 50/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0018 - val_loss: 0.0261 - val_mae: 0.0261 - val_mse: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0018 - val_loss: 0.0237 - val_mae: 0.0237 - val_mse: 0.0011\n",
      "Epoch 52/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0252 - mae: 0.0252 - mse: 0.0018 - val_loss: 0.0230 - val_mae: 0.0230 - val_mse: 0.0011\n",
      "Epoch 53/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0250 - mae: 0.0250 - mse: 0.0018 - val_loss: 0.0226 - val_mae: 0.0226 - val_mse: 0.0011\n",
      "Epoch 54/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0248 - mae: 0.0248 - mse: 0.0018 - val_loss: 0.0277 - val_mae: 0.0277 - val_mse: 0.0016\n",
      "Epoch 55/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0262 - mae: 0.0262 - mse: 0.0019 - val_loss: 0.0253 - val_mae: 0.0253 - val_mse: 0.0012\n",
      "Epoch 56/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0229 - val_mae: 0.0229 - val_mse: 0.0010\n",
      "Epoch 57/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0018 - val_loss: 0.0228 - val_mae: 0.0228 - val_mse: 0.0010\n",
      "Epoch 58/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0247 - val_mae: 0.0247 - val_mse: 0.0012\n",
      "Epoch 59/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0018 - val_loss: 0.0274 - val_mae: 0.0274 - val_mse: 0.0015\n",
      "Epoch 60/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0017 - val_loss: 0.0260 - val_mae: 0.0260 - val_mse: 0.0014\n",
      "Epoch 61/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0267 - mae: 0.0267 - mse: 0.0021 - val_loss: 0.0331 - val_mae: 0.0331 - val_mse: 0.0019\n",
      "Epoch 62/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0017 - val_loss: 0.0259 - val_mae: 0.0259 - val_mse: 0.0014\n",
      "Epoch 63/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0420 - val_mae: 0.0420 - val_mse: 0.0026\n",
      "Epoch 64/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0226 - val_mae: 0.0226 - val_mse: 0.0010\n",
      "Epoch 65/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0244 - mae: 0.0244 - mse: 0.0017 - val_loss: 0.0242 - val_mae: 0.0242 - val_mse: 0.0011\n",
      "Epoch 66/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0239 - val_mae: 0.0239 - val_mse: 0.0011\n",
      "Epoch 67/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0245 - mae: 0.0245 - mse: 0.0017 - val_loss: 0.0253 - val_mae: 0.0253 - val_mse: 0.0013\n",
      "Epoch 68/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0017 - val_loss: 0.0254 - val_mae: 0.0254 - val_mse: 0.0013\n",
      "Epoch 69/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0277 - val_mae: 0.0277 - val_mse: 0.0013\n",
      "Epoch 70/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0251 - mae: 0.0251 - mse: 0.0018 - val_loss: 0.0316 - val_mae: 0.0316 - val_mse: 0.0018\n",
      "Epoch 71/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0017 - val_loss: 0.0277 - val_mae: 0.0277 - val_mse: 0.0016\n",
      "Epoch 72/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0254 - mae: 0.0254 - mse: 0.0018 - val_loss: 0.0236 - val_mae: 0.0236 - val_mse: 0.0011\n",
      "Epoch 73/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0250 - val_mae: 0.0250 - val_mse: 0.0013\n",
      "Epoch 74/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0237 - mae: 0.0237 - mse: 0.0016 - val_loss: 0.0297 - val_mae: 0.0297 - val_mse: 0.0015\n",
      "Epoch 75/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0241 - mae: 0.0241 - mse: 0.0017 - val_loss: 0.0230 - val_mae: 0.0230 - val_mse: 0.0011\n",
      "Epoch 76/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0239 - mae: 0.0239 - mse: 0.0017 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0011\n",
      "Epoch 77/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0018 - val_loss: 0.0254 - val_mae: 0.0254 - val_mse: 0.0012\n",
      "Epoch 78/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0012\n",
      "Epoch 79/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0240 - mae: 0.0240 - mse: 0.0016 - val_loss: 0.0227 - val_mae: 0.0227 - val_mse: 0.0011\n",
      "Epoch 80/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0244 - mae: 0.0244 - mse: 0.0016 - val_loss: 0.0240 - val_mae: 0.0240 - val_mse: 0.0012\n",
      "Epoch 81/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0404 - val_mae: 0.0404 - val_mse: 0.0024\n",
      "Epoch 82/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0247 - mae: 0.0247 - mse: 0.0018 - val_loss: 0.0277 - val_mae: 0.0277 - val_mse: 0.0013\n",
      "Epoch 83/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0249 - mae: 0.0249 - mse: 0.0018 - val_loss: 0.0361 - val_mae: 0.0361 - val_mse: 0.0021\n",
      "Epoch 84/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0244 - mae: 0.0244 - mse: 0.0017 - val_loss: 0.0232 - val_mae: 0.0232 - val_mse: 0.0011\n",
      "Epoch 85/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0017 - val_loss: 0.0292 - val_mae: 0.0292 - val_mse: 0.0017\n",
      "Epoch 86/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0016 - val_loss: 0.0256 - val_mae: 0.0256 - val_mse: 0.0013\n",
      "Epoch 87/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0246 - mae: 0.0246 - mse: 0.0017 - val_loss: 0.0303 - val_mae: 0.0303 - val_mse: 0.0015\n",
      "Epoch 88/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0240 - mae: 0.0240 - mse: 0.0016 - val_loss: 0.0236 - val_mae: 0.0236 - val_mse: 0.0011\n",
      "Epoch 89/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0238 - mae: 0.0238 - mse: 0.0016 - val_loss: 0.0287 - val_mae: 0.0287 - val_mse: 0.0014\n",
      "Epoch 90/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0237 - mae: 0.0237 - mse: 0.0016 - val_loss: 0.0366 - val_mae: 0.0366 - val_mse: 0.0021\n",
      "Epoch 91/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0233 - mae: 0.0233 - mse: 0.0016 - val_loss: 0.0286 - val_mae: 0.0286 - val_mse: 0.0017\n",
      "Epoch 92/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0239 - mae: 0.0239 - mse: 0.0016 - val_loss: 0.0236 - val_mae: 0.0236 - val_mse: 0.0011\n",
      "Epoch 93/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0240 - mae: 0.0240 - mse: 0.0016 - val_loss: 0.0346 - val_mae: 0.0346 - val_mse: 0.0018\n",
      "Epoch 94/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0232 - mae: 0.0232 - mse: 0.0016 - val_loss: 0.0248 - val_mae: 0.0248 - val_mse: 0.0013\n",
      "Epoch 95/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0238 - mae: 0.0238 - mse: 0.0016 - val_loss: 0.0398 - val_mae: 0.0398 - val_mse: 0.0022\n",
      "Epoch 96/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0017 - val_loss: 0.0303 - val_mae: 0.0303 - val_mse: 0.0018\n",
      "Epoch 97/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0236 - mae: 0.0236 - mse: 0.0016 - val_loss: 0.0276 - val_mae: 0.0276 - val_mse: 0.0015\n",
      "Epoch 98/200\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 0.0242 - mae: 0.0242 - mse: 0.0016 - val_loss: 0.0229 - val_mae: 0.0229 - val_mse: 0.0011\n",
      "Epoch 99/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0243 - mae: 0.0243 - mse: 0.0016 - val_loss: 0.0298 - val_mae: 0.0298 - val_mse: 0.0014\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0238 - mae: 0.0238 - mse: 0.0016 - val_loss: 0.0260 - val_mae: 0.0260 - val_mse: 0.0012\n",
      "Epoch 101/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0238 - mae: 0.0238 - mse: 0.0015 - val_loss: 0.0346 - val_mae: 0.0346 - val_mse: 0.0019\n",
      "Epoch 102/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0234 - mae: 0.0234 - mse: 0.0015 - val_loss: 0.0242 - val_mae: 0.0242 - val_mse: 0.0013\n",
      "Epoch 103/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0235 - mae: 0.0235 - mse: 0.0016 - val_loss: 0.0257 - val_mae: 0.0257 - val_mse: 0.0015\n",
      "Epoch 104/200\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 0.0229 - mae: 0.0229 - mse: 0.0015 - val_loss: 0.0230 - val_mae: 0.0230 - val_mse: 0.0011\n",
      "1.1321122717955234\n"
     ]
    }
   ],
   "source": [
    "# 超参数\n",
    "# CNN-BiLSTM-AM\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import LSTM,Dense,Conv1D,MaxPooling1D,Activation,Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "def R2(pred, true):\n",
    "    return 1 - (np.sum((true-pred)**2)) / (np.sum((true-true.mean())**2))\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = tf.keras.initializers.get('glorot_uniform')\n",
    "        # W_regularizer: 权重上的正则化\n",
    "        # b_regularizer: 偏置项的正则化\n",
    "        self.W_regularizer = tf.keras.regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = tf.keras.regularizers.get(b_regularizer)\n",
    "        # W_constraint: 权重上的约束项\n",
    "        # b_constraint: 偏置上的约束项\n",
    "        self.W_constraint = tf.keras.constraints.get(W_constraint)\n",
    "        self.b_constraint = tf.keras.constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        \n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        \n",
    "        if self.bias:\n",
    "                    self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "            \n",
    "        self.built = True\n",
    "        \n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "        \n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                              K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "        \n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "            \n",
    "        eij = K.tanh(eij)\n",
    "        \n",
    "        a = K.exp(eij)\n",
    "        \n",
    "        '''\n",
    "        keras.backend.cast(x, dtype): 将张量转换到不同的 dtype 并返回\n",
    "        '''\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "            \n",
    "        '''\n",
    "        keras.backend.epsilon(): 返回浮点数\n",
    "        '''\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon()   , K.floatx())\n",
    "        \n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim\n",
    "\n",
    "class CustomEarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0):\n",
    "        super(CustomEarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"val_loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            print(\"learning_rate: \",self.learning_rate)\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 10:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# print(y_valid)\n",
    "# LSTM 参数: return_sequences=True LSTM输出为一个序列。默认为False，输出一个值。\n",
    "# input_dim： 输入单个样本特征值的维度\n",
    "# input_length： 输入的时间点长度\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64,kernel_size=1,activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(1))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(LSTM(units=100, return_sequences=True, input_dim=x_train.shape[-1], input_length=x_train.shape[1],activation='tanh'))\n",
    "model.add(keras.layers.Bidirectional(LSTM(units=64,return_sequences=True,activation='tanh')))\n",
    "# model.add(keras.layers.LSTM(units=64,return_sequences=True,activation='tanh'))\n",
    "model.add(Attention(5))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "EStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=70,\n",
    "                                         verbose=0,mode='min',baseline=None,\n",
    "                                         restore_best_weights=True)\n",
    "Learn_rate_adjust = tf.keras.callbacks.LearningRateScheduler(scheduler) \n",
    "\n",
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=x_train.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "optimizer_ad = AdamWarmup(total_steps, warmup_steps, learning_rate=1e-3, min_lr=1e-7)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=keras.losses.MAE, optimizer=adam, metrics=[\"mae\",\"mse\"])\n",
    "hist = model.fit(x_train, y_train, \n",
    "                 epochs=epochs,validation_data=(x_valid, y_valid), \n",
    "                 batch_size=batch_size, verbose=1,\n",
    "                callbacks=[EStop])\n",
    "# loss= model.evaluate(x_valid, u, verbose=0)\n",
    "# print(\"loss\",loss)\n",
    "\n",
    "\n",
    "print(y_valid[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b11c4f96",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# model.save('./Baseline_result/HSI/base_line_SPX', save_format='tf')\n",
    "#  \n",
    "# 加载模型，通过指定存放模型的文件夹来加载\n",
    "# new_model = keras.models.load_model('./Baseline_result/SZ/base_line_SZ')\n",
    "# new_price  = new_model.predict(x_valid)\n",
    "# # old_price = model.predict(x_valid)\n",
    "# print(new_price[:10],old_price[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c24c29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_=model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb62e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 5, 64)             576       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 5, 64)             0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 5, 128)           66048     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " attention (Attention)       (None, 128)               133       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,886\n",
      "Trainable params: 66,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# results = model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7eb2c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 660us/step\n"
     ]
    }
   ],
   "source": [
    "closing_price = model.predict(x_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d504f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452,)\n",
      "(452,)\n"
     ]
    }
   ],
   "source": [
    "print(closing_price[:, 0].shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb3df86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 929us/step\n",
      "mean :1664.2605341777041, std: 382.3092306775678 \n",
      "mae, rmse, R2,MAPE tf.Tensor(16.579945092989487, shape=(), dtype=float64) 26.23899357278189 0.9744865765938284 0.006280765636945135\n",
      "(452, 1)\n",
      "(452,)\n",
      "0.04336789112730759\n"
     ]
    }
   ],
   "source": [
    "closing_price = model.predict(x_valid)\n",
    "func = lambda y,y_: tf.reduce_mean(tf.abs(y-y_))\n",
    "# scaler.fit_transform(pd.DataFrame(valid['closeIndex'].values))\n",
    "# 反归一化\n",
    "closing_price = closing_price*std+mean\n",
    "# print(closing_price)\n",
    "# print(y_valid.shape)\n",
    "# closing_price = scaler.inverse_transform(closing_price)\n",
    "# print(y_valid.shape)\n",
    "# y_valid = y_valid.reshape(-1,1)\n",
    "# print(closing_price)\n",
    "# y_valid = scaler.inverse_transform([y_valid])\n",
    "y_valid = y_valid*std+mean\n",
    "# print(y_valid)\n",
    "# print(closing_price)\n",
    "mae = np.mean(np.abs(y_valid - closing_price[:, 0]))\n",
    "rms = np.sqrt(np.mean(np.power((y_valid - closing_price[:, 0]), 2)))\n",
    "R2 = 1 - (np.sum((y_valid-closing_price[:,0])**2)) / (np.sum((y_valid-y_valid.mean())**2))\n",
    "mape = np.mean(np.abs((y_valid - closing_price[:,0]) / y_valid))\n",
    "print(\"mean :{}, std: {} \".format(mean ,std))\n",
    "print(\"mae, rmse, R2,MAPE\", func(y_valid, closing_price[:, 0]),rms,R2,mape)\n",
    "# print(y_valid)\n",
    "print(closing_price.shape)\n",
    "print(y_valid.shape)\n",
    "print(mae/std)\n",
    "folder_path = './result/'\n",
    "np.save(folder_path + 'metrics.npy', np.array([mae, rms,R2]))\n",
    "np.save(folder_path + 'pred.npy', closing_price)\n",
    "\n",
    "np.save(folder_path + 'true.npy', y_valid)\n",
    "# print()\n",
    "# keras.losses.mean_absolute_error(y_valid, closing_price).numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e29e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :4054.0914889124524, std: 550.3340160245629 \n",
      "mae, rmse, R2,MAPE tf.Tensor(76.89748121732029, shape=(), dtype=float64) 91.646957118149 0.7495309451931067 0.014649123952162725\n"
     ]
    }
   ],
   "source": [
    "mae = np.mean(np.abs(y_valid - closing_price[:, 0]))\n",
    "rms = np.sqrt(np.mean(np.power((y_valid - closing_price[:, 0]), 2)))\n",
    "R2 = 1 - (np.sum((y_valid-closing_price[:,0])**2)) / (np.sum((y_valid-y_valid.mean())**2))\n",
    "mape = np.mean(np.abs((y_valid - closing_price[:,0]) / closing_price[:,0]))\n",
    "print(\"mean :{}, std: {} \".format(mean ,std))\n",
    "print(\"mae, rmse, R2,MAPE\", func(y_valid, closing_price[:, 0]),rms,R2,mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "0.014649123952162725"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7906f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1838,)\n",
      "(1838, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_valid.shape)\n",
    "print(closing_price.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54c4c241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # print(y_valid[0])\n",
    "# # plt.figure(figsize=(16, 8))\n",
    "# closing_price = closing_price.reshape(1,-1)\n",
    "# y_valid = y_valid.reshape(1,-1)\n",
    "# dict_data = {\n",
    "#     'Predictions': closing_price[0],\n",
    "#     'Close': y_valid[0],\n",
    "# }\n",
    "# data_pd = pd.DataFrame(dict_data)\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# plt.plot(y_valid[0], label='GroundTruth')\n",
    "# plt.plot(closing_price[0], label='Prediction')\n",
    "# plt.savefig('./Baseline_result/SZ/result.png')\n",
    "# plt.legend()\n",
    "# # plt.plot(data_pd[['Close','Predictions']])\n",
    "# # plt.plot(data_pd[['Predictions']])\n",
    "# plt.show()\n",
    "# # print(y_valid,closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a41e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM\t    CNN-BiLSTM-AM  for_test  IXIC  SH\tSZ\r\n",
      "CNN-BiLSTM  CNN-LSTM\t   HSI\t     LSTM  SPX\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./Baseline_result/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ef8fcefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 1) (1000, 1, 1) (6,)\n",
      "[2.27099838e+01 1.07799329e+03 3.28328094e+01 7.56923668e-03\n",
      " 1.23805759e-04 9.80309978e-01]\n",
      "0.007600347\n",
      "22.709984\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# def MAPE(pred, true):\n",
    "#     return np.mean(np.abs((pred - true) / true))\n",
    "# def MAE(pred, true):\n",
    "#     return np.mean(np.abs(pred - true))\n",
    "# folder_path = './Ablation_result/Autoformer_lag_size_10/SH/'\n",
    "# # np.save(folder_path + 'metrics.npy', np.array([mae, rms,R2]))\n",
    "# # np.save(folder_path + 'pred.npy', closing_price\n",
    "# preds = np.load(folder_path+'/pred.npy')\n",
    "# trues = np.load(folder_path+'/true.npy')\n",
    "# metrics = np.load(folder_path+'/metrics.npy')\n",
    "# mape = MAPE(preds,trues)\n",
    "# mae = MAE(preds,trues)\n",
    "# print(preds.shape, trues.shape, metrics.shape)\n",
    "# print(metrics)\n",
    "# print(mape)\n",
    "# print(mae)\n",
    "\n",
    "\n",
    "# # prediction = np.load('./results/'+setting+'/real_prediction.npy')\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib\n",
    "# # print(prediction.shape)\n",
    "# # print(prediction)\n",
    "# import seaborn as sns\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# # matplotlib.use('TKAgg')\n",
    "# # plt.plot(prediction[:,:,-1],label='prediction')\n",
    "# plt.plot(trues[:, -1], label='GroundTruth')\n",
    "# plt.plot(preds[:, -1], label='Prediction')\n",
    "# plt.savefig('./results/'+setting+'/result.png')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bfe84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "10px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
